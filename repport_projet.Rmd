---
title: "Rapport du projet"
author: "Aimé Cazeel"
date: "3 février 2020"
output: pdf_document
---

```{r, echo=FALSE, include=FALSE}
# Paramètre fixe
set.seed(42)

#Importation packages

library(readxl)
library(mice)
library(MASS)
library(pROC)
library(caret)
library(kernlab)
library(MLmetrics)

# Fonctions

cherche.ext<-function(x,taille=2){
  sigma<-sd(x,na.rm=TRUE) # pour recalculer plusieurs fois l'écart type
  ext<-mean(x,na.rm=TRUE)+c(-taille*sigma,2*sigma) # 2 valeurs de l'intervalle
  result<-(x>=ext[1])&(x<=ext[2]) # TRUE si ok, FALSE si extrême
  return(result)
  
  # on y rentre un vecteur de données
  # souvent on considère que ce qui s'écarte de 2 écart-type de la moyenne n'est pas normal
  # mais on va laisser le choix de la taille de cet intervalle (2 ou 3 sigma ?)
}

```

\newpage

# Résumé

Le CBSM ou Cognitive Behavioral Stress Management est un programme de gestion du stress qui mélange des exercices de relaxation, de restructuration cognitive et de dynamique de groupe.Si ce programme étudié principalement aux Etats-Unis s'avère efficace sur des maladies comme le cancer du sein ou le VIH, il n'existe cependant que peu d'études sur l'application du programme CBSM sur des patients atteints de maladies cardio-vasculaires et de son effet sur le stress, l'anxiété et les pensées intrusives.

Ainsi, l'objectif de ce document est d'étudier l'efficacité de ce programme auprès de patients atteints de maladies cardio-vasculaires. Pour cela, les patients ont été séparés en 2 groupes, un groupe témoin et un groupe participant au programme CBSM. Des mesures physiologiques ont étés relevés avant et après l'application du programme.

Une étude ultérieur ayant mis en valeur l'efficacité du programme concernant l'amélioration du stress perçu et de l'anxiété, nous cherchons ici à étudier l'efficacité du programme sur le stress ressenti.

<--- DO TO COMPLETER AVEC CONCLUSION  ---!>

\newpage

# Introduction

## Etat des lieux

Les maladies cardiovasculaires sont un ensemble de troubles affectant le coeur et les vaisseaux sanguins. Première cause de mortalité dans le monde selon l'OMS, elles nécessitent souvent une prise en charge lourde comprenant soutien psychologique et médicaments. Ainsi, il est important de trouver des solutions efficaces pour aider les personnes exposées à ces maladies.

Si l'alimentation et le tabagisme sont des facteurs aggravant connus, de nombreuses études mettent en évidence l'existence d'un lien entre stress et maladies cardio-vasculaires. Ainsi, proposer des solutions agissant sur le stress et ne nécessitant pas une prise en charge lourde ou médicamenteuse peut permettre de soulager les personnes atteintes de problèmes cardiovasculaires.

Or, il existe de nombreuses méthodes pour faciliter la gestion du stress, dont le CBSM.

## CBSM ou Cognitive Behavioral Stress Management

Le CBSM est un programme de gestion du stress qui mélange des exercices de relaxation, de restructuration cognitive et de dynamique de groupe.L'objectif est de permettre aux patients d'avoir accès à des connaisances sur eux-même, sur le stress et son impact, et sur les réactions psychologiques qu'il peut susciter. Il est constitué de plusieurs séances en groupe ainsi que d'exercices à réaliser chez soi.

Si ce programme étudié principalement aux Etats-Unis s'avére efficace sur des maladies comme le cancer du sein ou le VIH, il n'existe cependant que peu d'études sur l'application du programme CBSM sur des patients atteints de maladies cardio-vasculaires et de son effet sur le stress, l'anxiété et les pensées intrusives.

## Expérience

Ainsi en 2016 une expérience a été réalisé sur des patients atteints de pathologies cardiaques. Ces patients ont suivi le programme CBSM et ont répondus à des questionnaires afin d'évaluer leurs états psychologiques. De plus des relevés physiologiques ont aussi été réalisés. Les questionnaires doivent permettre d'évaluer le ressenti des patients par rapport au stress, tandis que les relevés physiologique permettent d'évaluer l'impact physique des interventions.

# Objectif

Ce document fait suite au travail rédigé par Franck D'ALESSANDRO mettant en avant l'efficacité du programme CBSM sur la diminution du stress perçu par les patients ainsi que leur anxiété, ainsi que le travail de Aimé CAZEEL confirmant une partie de ces résultats.

Le but de cette étude est donc d'analyser l'influence  du programme sur le stress "physique" des patients (que l'on distinguera du stress perçu).

```{r, echo=FALSE, results='hide',warning=FALSE}
# Importation des données

data_physio <- read_excel("./data/datas_physio_cbsm.xlsx",sheet=2)

# Formattage des noms des colonnes

# PHYSIO
##Renommage
colnames(data_physio)[5:21]<-c("T0_Mean_RR_ms","T0_STD_RR_ms","T0_Mean_HR_1_min","T0_STD_HR_1_min","T0_RMSSD_ms",
"T0_VLF_ms2","T0_LF_ms2","T0_HF_ms2","T0_VLF_pourcent","T0_LF_pourcent","T0_HF_pourcent","T0_LF_nu",
"T0_HF_nu","T0_Total_power_ms2","T0_LF_HF_ratio","T0_EDR_Hz","T0_Frequence_Respiratoire")

colnames(data_physio)[22:40]<-c("Espace_1","Espace_2","T1_Mean_RR_ms","T1_STD_RR_ms","T1_Mean_HR_1_min","T1_STD_HR_1_min","T1_RMSSD_ms",
"T1_VLF_ms2","T1_LF_ms2","T1_HF_ms2","T1_VLF_pourcent","T1_LF_pourcent","T1_HF_pourcent","T1_LF_nu",
"T1_HF_nu","T1_Total_power_ms2","T1_LF_HF_ratio","T1_EDR_Hz","T1_Frequence_Respiratoire")

colnames(data_physio)[41:57]<-c("T2_Mean_RR_ms","T2_STD_RR_ms","T2_Mean_HR_1_min","T2_STD_HR_1_min","T2_RMSSD_ms",
"T2_VLF_ms2","T2_LF_ms2","T2_HF_ms2","T2_VLF_pourcent","T2_LF_pourcent","T2_HF_pourcent","T2_LF_nu",
"T2_HF_nu","T2_Total_power_ms2","T2_LF_HF_ratio","T2_EDR_Hz","T2_Frequence_Respiratoire")

##suppression des colonnes espaces
data_physio<-data_physio[,!colnames(data_physio)%in%c("Espace_1","Espace_2")]
data_physio<-data_physio[,!colnames(data_physio)%in%c("T0_VLF_pourcent","T0_LF_pourcent","T0_HF_pourcent","T0_LF_nu","T0_HF_nu","T0_LF_HF_ratio","T0_EDR_Hz","T1_VLF_pourcent","T1_LF_pourcent","T1_HF_pourcent","T1_LF_nu","T1_HF_nu","T1_LF_HF_ratio","T1_EDR_Hz","T2_Mean_RR_ms","T2_STD_RR_ms","T2_Mean_HR_1_min","T2_STD_HR_1_min","T2_RMSSD_ms",
"T2_VLF_ms2","T2_LF_ms2","T2_HF_ms2","T2_VLF_pourcent","T2_LF_pourcent","T2_HF_pourcent","T2_LF_nu",
"T2_HF_nu","T2_Total_power_ms2","T2_LF_HF_ratio","T2_EDR_Hz","T2_Frequence_Respiratoire")]

num_var_T0<-5:14
num_var_T1<-15:24
nb_var_T0<-length(num_var_T0)
nb_var_T1<-length(num_var_T1)
```

\newpage
# Approche du problème

## Participants

Au départ, l'expérience porte sur 150 participants ayant développés une maladie cardiaque. 50 personnes participent au programme CBSM, 50 personnes participent à des séances la relaxation et 50 personnes sont des individus "contrôle" ne suivant pas de programme particulier (hormis les soins). Ces personnes proviennent de différent lieux dans l'aglomération de Grenoble :

* Service de réadaptation cardiaque de l'hôpital Sud (Echirolles)
* Institut cardio-vascualire du groupe hospitalier mutualiste de Grenoble
* Réseau des pathologies vasculaires GRANTED à Saint-Martin-d'Hères
* Service de cardiologie du CHU La Tronche
* Service de diabétologie du CHU La Tronche

Les patients sont recrutés par les équipes soignantes, les personnes acceptant de participés sont placés aléatoirement dans l'un des 3 groupes.

## Méthodes d'expérimentation

Le programme CBSM est constitué de plusieurs séances (2h par semaine) avec en plus des excercices à réaliser chez soi. Après l'ensemble des séances, les patients sont invités à répondre à des questionnaires mesurant leur perception du stress puis des mesure physiologiques sont prises. Ces mesures sont prises avec un module BIOPAC MP 150 qui va permettre de relever plusieurs variables.

Les mesures et les réponses aux questionnaires sont prises à différents moments :

* T0 : avant le début des séances CBSM
* T1 : à la fin des 10 semaines d'interventions
* T2 : 6 mois après l'intervention

### Mesure physiologique : HRV ou  Heart Rate Variability

Les recherches en psychophysiologie intègrent de plus en plus d'étude sur la variabilité du rythme cardiaque (HRV). En effet, il existe un lien entre le système nerveux parasympathique (lié à la régulation cardiaque) et de nombreux phénomènes psychophysiologique. Le HRV est d'ailleurs utilisé pour prédire les risques de mortalité provenant de cause mental ou physique.

Un relevé du HRV est simple à mettre en place et sans douleur, d'où son utilisation répandue. Parmis les nombreuses variables étudiables, celles d'intérêts sont :

* RMSSD (Root Mean Square of Succesive differences) dont les variations sont dépendantes du tonus vagal (activité du nerf vague, composant du sytème parasympathique contrôlant les activités involontaires des organes).
* HF (High Frenquencies) dont les variations proviennent aussi du tonus vagal mais peuvent être influencé par la respiration.
* LF (Low Frequencies) ainsi que le rapport LF/HF, dont les variations dépendent de divers éléments dont le système sympathique (responsable du rythme cardiaque mais aussi de la contraction des muscles lisses) et le tonus vagal.

Bien que facile à relever, le HRV est sujet à des erreurs de mesures ou à des modifications de celui-ci dû à des facteurs externes pouvant le rendre difficile à étudier (caféine etc...)

Dans les études statistiques, le HRV est très souvent utlisé comme une variable les régressions ou les corrélations, permettant souvent de distinguer des groupes selons d'autres critères (comme des différences individuelles). Parfois, le HRV peut être considéré comme une variable dépendante en créant 2 groupes séparés par la médiane. A ce moment, on suppose que le HRV illustre des particularité individuelles (on sait par exemple que le controle vagal est partiellement héritable, ce qui peut en faire une information propre à chaque individus et non dépendantes de variables externes).
 
Concernant la distribution des variables liées au HRV, la question de la normalité des variables est discutée. Mais des études tendent à observer une non normalité de la distribution de ces variables. La transformation logarithmique est alors une procédure courante pour remédier à ce problème.

## Analyses

L'analyse va se dérouler en plusieurs étapes, chacune cherchant à répondre à une problèmatique :

* Vérifier si il existe des différences à T0 entre nos groupes (les individus sont-ils homogènes au départ)
* Vérifier si il existe des différences entre T0 et T1 entre nos groupe (est ce qu'il y a du progrès)

### Limitations

#### Erreurs

Plusieurs problèmes apparaissent dans notre méthodologie :

* Si au départ, nous devions avoir 3 groupes, au final, seulement 2 groupes existent effectivement : les groupes CBSM et CONTROLE. Ces deux groupes sont de tailles différentes. De plus, le groupe CONTROLE réalise des exercices de relaxation.
* Des erreurs de mesures peuvent fausser nos résultats (erreurs de manipulation).De plus, nous faisons face à des individus sous médication ayant une pathologie cardiaque, les chances d'obtenir des valeurs extrêmes sont grandes. 

#### Durées de l'expérimentation

Les individus de l'expérience ont été exposé au programme pendant 10 semaines, sans obligations d'être présent à toute les séances, ni obligation à réaliser les exercices à faire chez soi, cela limite donc l'influence du programme sur nos patients.

Enfin, cette étude est basée sur le bénévolat. Hormis la volonté des patients, il n'y avait que peu d'obligations de poursuivre l'étude. Ainsi, nous observons une très grande absence de réponse pour les temps T2 (plusieurs mois après expérience). Nous avons aussi des patients absents lors des premières mesures, mais présent après etc.

Au final, au vu du faible de nombre de réponse pour le temps T2, nous avons décider de limiter nos analyses à T0 et T1, ne nous permettant pas de constater des résultats sur le long terme.

### Solutions facent aux limitations

#### Imputation



## Objectifs de l'analyse

Ainsi, nos objectifs sont donc les suivants :

* Corriger les valeurs extrêmes de certains patients, pour cela
* Déterminer un modèle de prédiction de l'amélioration de l'état d'un individu.

\newpage

# Premières analyses

## Données manquantes et premiers constats

Le premier problème dans notre jeu de données est la présence de données manquantes. Certaines personnes n'ont des données que concernant le temps T0 ou T1.

```{r, echo=FALSE}
# vecteur individus sans infos ) T0
vec_na_T0<-apply(X = data_physio[,num_var_T0],MARGIN = 1, FUN = function(x){sum(is.na(x))})
vec_na_T1<-apply(X = data_physio[,num_var_T1],MARGIN = 1, FUN = function(x){sum(is.na(x))})
vec_na_T0_T1<-apply(X = data_physio[,num_var_T0[1]:num_var_T1[length(num_var_T1)]],MARGIN = 1, FUN = function(x){sum(is.na(x))})
```

En effet, sur les `r nrow(data_physio)` individus du jeu de données de départ, `r sum(vec_na_T0==17)` n'ont pas de valeurs à T0, `r sum(vec_na_T1==17)` n'ont pas de données à T1 et `r sum(vec_na_T0_T1==34)` n'ont pas de données à T0 et T1.

Si nous pouvons par la suite discuter de l'intérêt de conserver des individus à qui il manque des données à T0 ou T1, il semble relativement logique de ce débarasser des individus sans données à T0 et T1 (il s'agit des personnes présentent seulement au temps T2), qui seront sans intérêt dans notre cos.

```{r, echo=FALSE}
# on modifie  les données de départ en se débarassant des personnes sans données en T0 et T1
data_physio<-data_physio[vec_na_T0_T1<=nb_var_T0,]
data_physio[is.na(data_physio$`Numéro HRV`),"Numéro HRV"]<-c(9998,9999)
data_physio<-data_physio[!(data_physio$`Numéro HRV`==87&data_physio$Groupe=="CBSM"),]
data_physio[data_physio$`Numéro HRV`==24,"Numéro HRV"]<-c(24,9997)
# Recalcul de ces vecteurs
vec_na_T0<-apply(X = data_physio[,num_var_T0],MARGIN = 1, FUN = function(x){sum(is.na(x))})
vec_na_T1<-apply(X = data_physio[,num_var_T1],MARGIN = 1, FUN = function(x){sum(is.na(x))})
```

Cela nous laisse alors avec `r nrow(data_physio)`, dont `r sum(vec_na_T0==17)` sans données à T0 et `r sum(vec_na_T1==17)` sans données à T1.

## Valeurs extrêmes

Le second problème est la présence de valeurs abérantes.

```{r, echo=FALSE}
T0_indi_sp<-apply(apply(data_physio[vec_na_T0==0,num_var_T0],2, cherche.ext),1,sum)==nb_var_T0
T1_indi_sp<-apply(apply(data_physio[vec_na_T1==0,num_var_T1],2, cherche.ext),1,sum)==nb_var_T1
```

En effet, sur les `r length(T0_indi_sp)` individus du jeu de données de départ avec des valeurs à T0, `r sum(T0_indi_sp==FALSE)` ont aun moins une valeur extrème, et sur les `r length(T1_indi_sp)` individus avec des valeurs à T1, `r sum(T1_indi_sp==FALSE)` ont au moins une valeur extrême.

# Imputation des données

Notre but premier est de remplacer les valeurs extrêmes chez nos individus. Au départ notre population est dans le même état (pas de groupe particulier à l'intérieur <-- A VERIFIER SI LE TEMPS --!>), nous pouvons donc utiliser l'ensemble des données disponible pour réaliser une imputation de données sans trop de problème.

Nous allons exclure les données manquantes de l'imputation. Imputer les valeurs manquantes au temps T1 reviendrait à prédire l'amélioration ou non de l'état de santé des patients, ce qui est certe l'objectif, mais nous nous limitons à indiquer si oui ou non il y a amélioration, nous ne souhaitons pas prédire l'ensemble des valeurs physiologique. Nous risquons alors d'influencer de façon non négligeable nos données.

Nous nous concentrerons donc seulement sur les valeurs abérantes

## Imputation à T0

```{r, echo=FALSE}
# Création du jeu de données à imputer avec des NA pour les valeurs extrêmes.

imput_T0<-cbind(data_physio[vec_na_T0==0,"Numéro HRV"],apply(data_physio[vec_na_T0==0,num_var_T0],2, FUN=function(x){
  need_replace<-!(cherche.ext(x))
  xbis<-x
  xbis[need_replace]<-NA
  return(xbis)})
)
```

Regardons le taux de valeur abérante pour chaque varialbe à T0

```{r, echo=FALSE}
# FAIRE UN JOLIE TABLEAU !!
apply(imput_T0[,-1],2,function(x){sum(is.na(x))/length(x)*100})

```
On observe que majoritairement, nous n'avons pas de de variables avec un pourcentage trop important (au dela de 10%) de valeur abérante. Nous allons donc imputer l'ensemble des variables.

### Imputation par la moyenne prévisionnelle

L'idée ici est de chercher les individus proches des individus avec des valeurs manquantes, puis de compléter ces valeurs manquantes avec la moyenne de ces individus.

```{r, echo=FALSE}
init_T0 = mice(imput_T0[,-1], maxit=0) 
meth = init_T0$method
predM = init_T0$predictorMatrix

imputed_T0 <- mice(imput_T0[,-1], method=meth, predictorMatrix=predM, m=5)
imput_T0_mean <- cbind(data_physio[vec_na_T0==0,"Numéro HRV"],complete(imputed_T0))
```

<-- AUTRES METHODES ? --!>

### Comparaison des méthodes

```{r, echo=FALSE}
summary(imput_T0[,-1])
summary(imput_T0_mean[,-1])
```

## Imputation à T1

```{r, echo=FALSE}
# Création du jeu de données à imputer avec des NA pour les valeurs extrêmes.

imput_T1<-cbind(data_physio[vec_na_T1==0,"Numéro HRV"],apply(data_physio[vec_na_T1==0,num_var_T1],2, FUN=function(x){
  need_replace<-!(cherche.ext(x))
  xbis<-x
  xbis[need_replace]<-NA
  return(xbis)})
)
```

### Imputation par la moyenne prévisionnelle

```{r, echo=FALSE}
init_T1 = mice(imput_T1[,-1], maxit=0)    
meth = init_T1$method
predM = init_T1$predictorMatrix

imputed_T1 <- mice(imput_T1[,-1], method=meth, predictorMatrix=predM, m=5)
imput_T1_mean <- cbind(data_physio[vec_na_T1==0,"Numéro HRV"],complete(imputed_T1))
```


```{r}
summary(imput_T1[,-1])
summary(imput_T1_mean[,-1])
```

<-- AUTRES METHODES ? --!>

### Test de différentes méthodes

### Création des valeurs NA dans le jeu de données complet

```{r, echo=FALSE}
T1_full<- imput_T1[apply(imput_T1,1,function(imput_T1) !any(is.na(imput_T1))),]
T1P<-T1_full

#T1P valeur complete
#T1_full valeur avec données manquantes

T1_full[9,2]<-NA
T1_full[30,2]<-NA
T1_full[36,3]<-NA
T1_full[23,3]<-NA
T1_full[26,4]<-NA
T1_full[38,4]<-NA
T1_full[38,5]<-NA
T1_full[29,5]<-NA

T1_full[43,6]<-NA
T1_full[35,6]<-NA
T1_full[1,7]<-NA
T1_full[11,7]<-NA
T1_full[8,8]<-NA
T1_full[25,8]<-NA
T1_full[20,9]<-NA
T1_full[31,9]<-NA

T1_full[34,10]<-NA
T1_full[27,10]<-NA
T1_full[37,11]<-NA
T1_full[42,11]<-NA
T1_full[28,11]<-NA
T1_full[12,11]<-NA
T1_full[14,6]<-NA
T1_full[14,8]<-NA
T1_full[12,5]<-NA

```
Nous avons créer un jeu de données contenant des valeurs manquantes afin de tester plus tard avec les différentes méthodes d'imputations laquelle minimise les erreurs de prédictions

### Les 5 différentes méthodes testées: (pmm, cart, sample, mean, norm)
```{r, echo=FALSE}
# Predictive mean matching (pmm)
init_T1P = mice(T1_full[,-1] ,maxit=0) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full[,-1], method= c("pmm"), predictorMatrix=predM,  m=5)
imput_T1P_pmm <- cbind(T1_full[,"Numéro HRV"],complete(imputed_T1P))


R_pmm<-round(c(
MSE(imput_T1P_pmm[,2],T1P[,2]),
MSE(imput_T1P_pmm[,3],T1P[,3]),
MSE(imput_T1P_pmm[,4],T1P[,4]),
MSE(imput_T1P_pmm[,5],T1P[,5]),
MSE(imput_T1P_pmm[,6],T1P[,6]),
MSE(imput_T1P_pmm[,7],T1P[,7]),
MSE(imput_T1P_pmm[,8],T1P[,8]),
MSE(imput_T1P_pmm[,9],T1P[,9]),
MSE(imput_T1P_pmm[,10],T1P[,10]),
MSE(imput_T1P_pmm[,11],T1P[,11])
) ,3)

summary(T1P[,-1])
summary(T1_full[,-1])
summary(imput_T1P_pmm[,-1])

```


## Unconditional mean imputation (mean)
```{r, echo=FALSE}

init_T1P = mice(T1_full[,-1], maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full[,-1], method= c("mean"), predictorMatrix=predM,  m=5)
imput_T1P_mean <- cbind(T1_full[,"Numéro HRV"],complete(imputed_T1P))

R_mean<-round(c(
MSE(imput_T1P_mean[,2],T1P[,2]),
MSE(imput_T1P_mean[,3],T1P[,3]),
MSE(imput_T1P_mean[,4],T1P[,4]),
MSE(imput_T1P_mean[,5],T1P[,5]),
MSE(imput_T1P_mean[,6],T1P[,6]),
MSE(imput_T1P_mean[,7],T1P[,7]),
MSE(imput_T1P_mean[,8],T1P[,8]),
MSE(imput_T1P_mean[,9],T1P[,9]),
MSE(imput_T1P_mean[,10],T1P[,10]),
MSE(imput_T1P_mean[,11],T1P[,11])
) ,3)

summary(T1P[,-1])
summary(T1_full[,-1])
summary(imput_T1P_mean[,-1])

```



# Classification and regression trees(cart)
```{r, echo=FALSE}

init_T1P = mice(T1_full[,-1], maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full[,-1], method= c("cart"), predictorMatrix=predM,  m=5)
imput_T1P_cart <- cbind(T1_full[,"Numéro HRV"],complete(imputed_T1P))

R_cart<-round(c(
MSE(imput_T1P_cart[,2],T1P[,2]),
MSE(imput_T1P_cart[,3],T1P[,3]),
MSE(imput_T1P_cart[,4],T1P[,4]),
MSE(imput_T1P_cart[,5],T1P[,5]),
MSE(imput_T1P_cart[,6],T1P[,6]),
MSE(imput_T1P_cart[,7],T1P[,7]),
MSE(imput_T1P_cart[,8],T1P[,8]),
MSE(imput_T1P_cart[,9],T1P[,9]),
MSE(imput_T1P_cart[,10],T1P[,10]),
MSE(imput_T1P_cart[,11],T1P[,11])
) ,3)

summary(T1P[,-1])
summary(T1_full[,-1])
summary(imput_T1P_cart[,-1])

```



# Random sample from observed values(sample)
```{r, echo=FALSE}

init_T1P = mice(T1_full[,-1], maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full[,-1], method= c("sample"), predictorMatrix=predM,  m=5)
imput_T1P_sample <- cbind(T1_full[,"Numéro HRV"],complete(imputed_T1P))


R_sample<-round(c(
MSE(imput_T1P_sample[,2],T1P[,2]),
MSE(imput_T1P_sample[,3],T1P[,3]),
MSE(imput_T1P_sample[,4],T1P[,4]),
MSE(imput_T1P_sample[,5],T1P[,5]),
MSE(imput_T1P_sample[,6],T1P[,6]),
MSE(imput_T1P_sample[,7],T1P[,7]),
MSE(imput_T1P_sample[,8],T1P[,8]),
MSE(imput_T1P_sample[,9],T1P[,9]),
MSE(imput_T1P_sample[,10],T1P[,10]),
MSE(imput_T1P_sample[,11],T1P[,11])
) ,3)

summary(T1P[,-1])
summary(T1_full[,-1])
summary(imput_T1P_sample[,-1])

```



# Bayesian linear regression (norm)
```{r, echo=FALSE}

init_T1P = mice(T1_full[,-1], maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full[,-1], method= c("norm"), predictorMatrix=predM,  m=5)
imput_T1P_norm <- cbind(T1_full[,"Numéro HRV"],complete(imputed_T1P))


R_norm<-round(c(
MSE(imput_T1P_norm[,2],T1P[,2]),
MSE(imput_T1P_norm[,3],T1P[,3]),
MSE(imput_T1P_norm[,4],T1P[,4]),
MSE(imput_T1P_norm[,5],T1P[,5]),
MSE(imput_T1P_norm[,6],T1P[,6]),
MSE(imput_T1P_norm[,7],T1P[,7]),
MSE(imput_T1P_norm[,8],T1P[,8]),
MSE(imput_T1P_norm[,9],T1P[,9]),
MSE(imput_T1P_norm[,10],T1P[,10]),
MSE(imput_T1P_norm[,11],T1P[,11])
) ,3)

summary(T1P[,-1])
summary(T1_full[,-1])
summary(imput_T1P_norm[,-1])

```


Comparaison des différentes méthodes d'imputations
```{r}
R_mse<- cbind( R_pmm, R_mean, R_cart,R_sample,R_norm)
R_compare<-cbind(R_mse, apply(R_mse, 1, min))
View (R_compare)
```

Pour notre imputation de données nous avions choisi de faire un premier test de différentes méthodes d’imputation sur le jeu de données. En première étape il s’agit de de récupérer une partie du jeu de données assez complète afin de recréer des valeurs manquantes et de comparer plus tard les résultats des différentes méthodes d’imputations que nous allons effectuer sur le jeu de données. 

Nous nous sommes basées sur la fonction MICE de la librairie mice qui renferme en elle différentes méthodes d’imputations. De cette liste de fonction, 5 types d’imputations ont été adoptés. Il s’agit de la Predictive mean matching PMM, la moyenne MEAN, Classification and regression trees CART, Random sample for observed values SAMPLE et une dernière le Bayesian Linear Regression NORM.

Le critère de comparaison est assez sur la minimisation des erreurs de prédiction le MSE entre les valeurs prédites par les imputations et les valeurs réelles. 
Et aussi en observant les statistiques descriptives avant et après les imputations.

Pour le choix du meilleur modèle d’imputation, choisir celle qui minimise au mieux sur l’ensemble des 10 variables et aussi sur la variable RM_SSD.

A la fin de ce test nous avons retenu 3 types d’imputations qui marchent le mieux. Le PMM et le Bayesian linear régression et la moyenne. Nous avions donc dégagé pour une première étape les trois méthodes qui seront choisies comme méthode à analyser.

La régression linéaire bayésienne est une approche de la régression linéaire dans laquelle l’analyse statistique est entreprise dans le contexte de l’inférence bayésienne.

La méthode de la moyenne utilise la moyenne obtenue sans les valeurs manquantes et les impute la même valeur à l’ensemble des valeurs manquantes

Par rapport aux méthodes standard basées sur la régression linéaire et la distribution normale, PMM produit des valeurs imputées qui ressemblent beaucoup plus à des valeurs réelles. Si la variable d'origine est asymétrique, les valeurs imputées seront également asymétriques. Si la variable d'origine est limitée par 0 et 100, les valeurs imputées seront également limitées par 0 et 100. Et si les valeurs réelles sont discrètes (comme le nombre d'enfants), les valeurs imputées seront également discrètes. En effet, les valeurs imputées sont des valeurs réelles qui sont «empruntées» à des individus disposant de données réelles.

Cependant en faisant une analyse des trois méthodologies d’imputations nous observons que les deux premières méthodes à savoir la bayesienne et le PMM minimise au mieux mais restent instable quand à la prédiction des valeurs, ce qui n’est pas le cas pour la moyenne. Et également en comparant les statistiques descriptives des variables avant et après les imputations, la moyenne semble mieux conserver les statistiques. 
Nous avons donc opté au final pour une imputation par la moyenne.

### Imputation de T1 par la moyenne

```{r, echo=FALSE}
init_T1 = mice(imput_T1[,-1], maxit=0)    
meth = init_T1$method
predM = init_T1$predictorMatrix

imputed_T1 <- mice(imput_T1[,-1], method="mean", predictorMatrix=predM, m=5)
imput_T1_mean <- cbind(data_physio[vec_na_T1==0,"Numéro HRV"],complete(imputed_T1))
```

### Comparaison des méthodes

```{r, echo=FALSE}
summary(imput_T1[,-1])
summary(imput_T1_mean[,-1])
```

En observant par exemple pour la variable RMSSD avant imputation et après imputation, nous obtenons la même moyenne, ce qui est normal par rapport à la methode utilisée et la troisième quartile qui varie de 42 à 39, la médiane qui était de 26,5 passe à 27,4. Notre imputation n'a pas eu d'impact énorme sur notre jeu de données.

## Fichier final

IL SEMBLE Y AVOIR UN PROBLEME AVOIR LA PREDICTION DE LA FREQUENCE RESPIRATOIRE. POUR LE MOMENT ELLE EST ENLEVE

```{r,echo=FALSE}
merge_data<-merge(imput_T0_mean[imput_T0_mean$`Numéro HRV` %in% imput_T1_mean$`Numéro HRV`,-18],imput_T1_mean[,-18],by="Numéro HRV")
merge_data$"progress"<-as.factor(ifelse(merge_data$T0_RMSSD_ms>merge_data$T1_RMSSD_ms,1,0))
print(table(merge_data$progress)/nrow(merge_data))
```

# Construction de modèles

## Partition

```{r}
trainIndex <- createDataPartition(merge_data$progress,p=0.77,list=F)
data_train<-merge_data[trainIndex,-c(1,18:33)]
table(data_train$progress)
data_test<-merge_data[-trainIndex,-c(1,18:33)]
table(data_test$progress)
```

## Regression logistique

```{r}
fitControl <- trainControl(method="cv",number=4)

reg_log<-train(progress~.,data = data_train, method="glmStepAIC",trControl=fitControl)
print(reg_log$finalModel)
```

### Importance des variables

```{r}
print(varImp(reg_log))
```

### Modele final

```{r}
reg_log$finalModel
```

## SVM

```{r}
#paramètres d'apprentissage
fitControl <- trainControl(method="cv",number=5)
#modélisation avec paramètre de la technique d'apprentissage
#SVM avec noyau linéaire, C = 0.1
m_svm <- train(progress ~ ., data =
data_train,method="svmLinear",trControl=fitControl,tuneGrid=data.frame(C=c(0.05,0.1,0.5,1,10)))
print(m_svm)

```


## Test

### Regression logistique

```{r}
reg_log$resample
```


```{r}
reg_log_pred<-predict(reg_log,newdata=data_test)
mat <- confusionMatrix(data=reg_log_pred,reference=data_test$progress,positive="1")
print(mat)

```

```{r}
#score <- predict(reg_log,merge_data[-trainIndex,-1],type="prob")[,"1"]
##objet roc
#roc_obj <- roc(merge_data[-trainIndex,"progress"]=="1",score)
##plot de l'objet roc
#plot(1-roc_obj$specificities,roc_obj$sensitivities,type="l")
#abline(0,1)
```

### SVM

```{r}
confusionMatrix(data=predict(m_svm,newdata = data_test),reference=data_test$progress,positive="1")

```

## VERSION TOUT EN UN

```{r}
#fonction pour train-test
#approche indique la technique de machine learning à évaluer
evaluation <- function(approche,cv_number=3){
 modele <- train(progress ~ ., data=data_train, trControl=trainControl(method="cv",number=cv_number), method=approche)
 prediction <- predict(modele,newdata=data_test)
 res <- confusionMatrix(data=prediction,reference=data_test$progress,positive="1")
 return(c(max(modele$results[,"Accuracy"]),res$overall["Accuracy"]))
}
```

```{r}
#liste des méthodes à tester
methodes <- c("glm","lda","svmLinear") # cforest, glmStepAIC, glmnet,logreg ...knn3
#lancement de l'expérimentation
perfs <- sapply(methodes,evaluation)
#mise en forme des résultats
colnames(perfs) <- methodes
rownames(perfs) <- c("CV","Test set")
#affichage
print(perfs)
```

