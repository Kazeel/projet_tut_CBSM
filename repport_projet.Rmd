---
title: "Rapport du projet"
author: "Aimé Cazeel"
date: "3 février 2020"
output: pdf_document
---

```{r, echo=FALSE, include=FALSE}
# Paramètre fixe
set.seed(10000)

#Importation packages

library(readxl)
library(mice)
library(MASS)
library(pROC)
library(caret)
library(kernlab)

library(klaR)
library(randomForest)
library(MLmetrics)
library(missForest)

# Fonctions

cherche.ext<-function(x,taille=2){
  sigma<-sd(x,na.rm=TRUE) # pour recalculer plusieurs fois l'écart type
  ext<-mean(x,na.rm=TRUE)+c(-taille*sigma,2*sigma) # 2 valeurs de l'intervalle
  result<-(x>=ext[1])&(x<=ext[2]) # TRUE si ok, FALSE si extrême
  return(result)
  
  # on y rentre un vecteur de données
  # souvent on considère que ce qui s'écarte de 2 écart-type de la moyenne n'est pas normal
  # mais on va laisser le choix de la taille de cet intervalle (2 ou 3 sigma ?)
}

remplace.data<-function(x,random=TRUE,ligne=NA,colonne=NA,nombre=NA){
  # permet de faire des trous dans un jeu de donnée
  data<-x
  
  if (is.na(nombre)) {
    nombre = floor(nrow(x)*ncol(x)*5/100)
  }
    
  
  if (random==TRUE) {
    nombre = floor(nrow(x)*ncol(x)*5/100)
    ligne<-sample(x = 1:nrow(x),size=nombre,replace = TRUE)
    colonne<-sample(x = 1:ncol(x),size=nombre,replace = TRUE)
  }
  for (i in 1:lengthh(ligne)) {
    data[ligne[i],colonne[i]]<-NA
  }
  
  return(list("data"=data,"ligne"=ligne,"colonne"=colonne))
}

```

\newpage

# Résumé

Le CBSM ou Cognitive Behavioral Stress Management est un programme de gestion du stress qui mélange des exercices de relaxation, de restructuration cognitive et de dynamique de groupe.Si ce programme étudié principalement aux Etats-Unis s'avère efficace sur des maladies comme le cancer du sein ou le VIH, il n'existe cependant que peu d'études sur l'application du programme CBSM sur des patients atteints de maladies cardio-vasculaires et de son effet sur le stress, l'anxiété et les pensées intrusives.

Ainsi, l'objectif de ce document est d'étudier l'efficacité de ce programme auprès de patients atteints de maladies cardio-vasculaires. Pour cela, les patients ont été séparés en 2 groupes, un groupe témoin et un groupe participant au programme CBSM. Des mesures physiologiques ont étés relevés avant et après l'application du programme.

Une étude ultérieur ayant mis en valeur l'efficacité du programme concernant l'amélioration du stress perçu et de l'anxiété, nous cherchons ici à étudier l'efficacité du programme sur le stress ressenti.

<--- DO TO COMPLETER AVEC CONCLUSION  ---!>

\newpage

# Introduction

## Etat des lieux

Les maladies cardiovasculaires sont un ensemble de troubles affectant le coeur et les vaisseaux sanguins. Première cause de mortalité dans le monde selon l'OMS, elles nécessitent souvent une prise en charge lourde comprenant soutien psychologique et médicaments. Ainsi, il est important de trouver des solutions efficaces pour aider les personnes exposées à ces maladies.

Si l'alimentation et le tabagisme sont des facteurs aggravant connus, de nombreuses études mettent en évidence l'existence d'un lien entre stress et maladies cardio-vasculaires. Ainsi, proposer des solutions agissant sur le stress et ne nécessitant pas une prise en charge lourde ou médicamenteuse peut permettre de soulager les personnes atteintes de problèmes cardiovasculaires.

Or, il existe de nombreuses méthodes pour faciliter la gestion du stress, dont le programme CBSM.

## CBSM ou Cognitive Behavioral Stress Management

Le CBSM est un programme de gestion du stress qui mélange des exercices de relaxation, de restructuration cognitive et de dynamique de groupe.L'objectif est de permettre aux patients d'avoir accès à des connaisances sur eux-même, sur le stress et son impact, et sur les réactions psychologiques qu'il peut susciter. Il est constitué de plusieurs séances en groupe ainsi que d'exercices à réaliser chez soi.

Si ce programme étudié principalement aux Etats-Unis s'avére efficace sur des maladies comme le cancer du sein ou le VIH, il n'existe cependant que peu d'études sur l'application du programme CBSM sur des patients atteints de maladies cardio-vasculaires et de son effet sur le stress, l'anxiété et les pensées intrusives.

## Expérience

Ainsi en 2016 une expérience a été réalisé sur des patients atteints de pathologies cardiaques. Ces patients ont suivi le programme CBSM et ont répondus à des questionnaires afin d'évaluer leurs états psychologiques. De plus des relevés physiologiques ont aussi été réalisés. Les questionnaires doivent permettre d'évaluer le ressenti des patients par rapport au stress, tandis que les relevés physiologique permettent d'évaluer l'impact physique des interventions.

# Objectif

Ce document fait suite au travail rédigé par Franck D'ALESSANDRO mettant en avant l'efficacité du programme CBSM sur la diminution du stress perçu par les patients ainsi que leur anxiété, ainsi que le travail de Aimé CAZEEL confirmant une partie de ces résultats.

Le but de cette étude est donc d'analyser l'influence  du programme sur le stress "physique" des patients (que l'on distinguera du stress perçu).

```{r, echo=FALSE, results='hide',warning=FALSE}
# Importation des données

data_physio <- read_excel("./data/datas_physio_cbsm.xlsx",sheet=2)

# Formattage des noms des colonnes

# PHYSIO
##Renommage
colnames(data_physio)[5:21]<-c("T0_Mean_RR_ms","T0_STD_RR_ms","T0_Mean_HR_1_min","T0_STD_HR_1_min","T0_RMSSD_ms",
"T0_VLF_ms2","T0_LF_ms2","T0_HF_ms2","T0_VLF_pourcent","T0_LF_pourcent","T0_HF_pourcent","T0_LF_nu",
"T0_HF_nu","T0_Total_power_ms2","T0_LF_HF_ratio","T0_EDR_Hz","T0_Frequence_Respiratoire")

colnames(data_physio)[22:40]<-c("Espace_1","Espace_2","T1_Mean_RR_ms","T1_STD_RR_ms","T1_Mean_HR_1_min","T1_STD_HR_1_min","T1_RMSSD_ms",
"T1_VLF_ms2","T1_LF_ms2","T1_HF_ms2","T1_VLF_pourcent","T1_LF_pourcent","T1_HF_pourcent","T1_LF_nu",
"T1_HF_nu","T1_Total_power_ms2","T1_LF_HF_ratio","T1_EDR_Hz","T1_Frequence_Respiratoire")

colnames(data_physio)[41:57]<-c("T2_Mean_RR_ms","T2_STD_RR_ms","T2_Mean_HR_1_min","T2_STD_HR_1_min","T2_RMSSD_ms",
"T2_VLF_ms2","T2_LF_ms2","T2_HF_ms2","T2_VLF_pourcent","T2_LF_pourcent","T2_HF_pourcent","T2_LF_nu",
"T2_HF_nu","T2_Total_power_ms2","T2_LF_HF_ratio","T2_EDR_Hz","T2_Frequence_Respiratoire")

##suppression des colonnes espaces
data_physio<-data_physio[,!colnames(data_physio)%in%c("Espace_1","Espace_2")]
data_physio<-data_physio[,!colnames(data_physio)%in%c("T0_VLF_pourcent","T0_LF_pourcent","T0_HF_pourcent","T0_LF_nu","T0_HF_nu","T0_LF_HF_ratio","T0_EDR_Hz","T1_VLF_pourcent","T1_LF_pourcent","T1_HF_pourcent","T1_LF_nu","T1_HF_nu","T1_LF_HF_ratio","T1_EDR_Hz","T2_Mean_RR_ms","T2_STD_RR_ms","T2_Mean_HR_1_min","T2_STD_HR_1_min","T2_RMSSD_ms",
"T2_VLF_ms2","T2_LF_ms2","T2_HF_ms2","T2_VLF_pourcent","T2_LF_pourcent","T2_HF_pourcent","T2_LF_nu",
"T2_HF_nu","T2_Total_power_ms2","T2_LF_HF_ratio","T2_EDR_Hz","T2_Frequence_Respiratoire")]

num_var_T0<-5:14
num_var_T1<-15:24
nb_var_T0<-length(num_var_T0)
nb_var_T1<-length(num_var_T1)
```

\newpage

# Approche du problème

## Participants

Au départ, l'expérience porte sur 150 participants ayant développés une maladie cardiaque. 50 personnes participent au programme CBSM, 50 personnes participent à des séances la relaxation et 50 personnes sont des individus "contrôle" ne suivant pas de programme particulier (hormis les soins). Ces personnes proviennent de différent lieux dans l'aglomération de Grenoble :

* Service de réadaptation cardiaque de l'hôpital Sud (Echirolles)
* Institut cardio-vascualire du groupe hospitalier mutualiste de Grenoble
* Réseau des pathologies vasculaires GRANTED à Saint-Martin-d'Hères
* Service de cardiologie du CHU La Tronche
* Service de diabétologie du CHU La Tronche

Les patients sont recrutés par les équipes soignantes, les personnes acceptant de participés sont placés aléatoirement dans l'un des 3 groupes.

## Méthodes d'expérimentation

Le programme CBSM est constitué de plusieurs séances (2h par semaine) avec en plus des excercices à réaliser chez soi. Après l'ensemble des séances, les patients sont invités à répondre à des questionnaires mesurant leur perception du stress puis des mesure physiologiques sont prises. Ces mesures sont prises avec un module BIOPAC MP 150 qui va permettre de relever plusieurs variables.

Les mesures et les réponses aux questionnaires sont pris à différents moments :

* T0 : avant le début des séances CBSM
* T1 : à la fin des 10 semaines d'interventions
* T2 : 6 mois après l'intervention

### Mesure physiologique : HRV ou  Heart Rate Variability

Les recherches en psychophysiologie intègrent de plus en plus d'étude sur la variabilité du rythme cardiaque (HRV). En effet, il existe un lien entre le système nerveux parasympathique (lié à la régulation cardiaque) et de nombreux phénomènes psychophysiologique. Le HRV est d'ailleurs utilisé pour prédire les risques de mortalité provenant de cause mental ou physique.

Un relevé du HRV est simple à mettre en place et sans douleur, d'où son utilisation répandue. Parmis les nombreuses variables étudiables, celles d'intérêts sont :

* RMSSD (Root Mean Square of Succesive differences) dont les variations sont dépendantes du tonus vagal (activité du nerf vague, composant du sytème parasympathique contrôlant les activités involontaires des organes).
* HF (High Frenquencies) dont les variations proviennent aussi du tonus vagal mais peuvent être influencé par la respiration.
* LF (Low Frequencies) ainsi que le rapport LF/HF, dont les variations dépendent de divers éléments dont le système sympathique (responsable du rythme cardiaque mais aussi de la contraction des muscles lisses) et le tonus vagal.

Bien que facile à relever, le HRV est sujet à des erreurs de mesures ou à des modifications de celui-ci dû à des facteurs externes pouvant le rendre difficile à étudier (caféine etc...)

Dans les études statistiques, le HRV est très souvent utlisé comme une variable les régressions ou les corrélations, permettant souvent de distinguer des groupes selons d'autres critères (comme des différences individuelles). Parfois, le HRV peut être considéré comme une variable dépendante en créant 2 groupes séparés par la médiane. A ce moment, on suppose que le HRV illustre des particularité individuelles (on sait par exemple que le controle vagal est partiellement héritable, ce qui peut en faire une information propre à chaque individus et non dépendantes de variables externes).
 
Concernant la distribution des variables liées au HRV, la question de la normalité des variables est discutée. Mais des études tendent à observer une non normalité de la distribution de ces variables. La transformation logarithmique est alors une procédure courante pour remédier à ce problème.

## Limitations

### Erreurs

Plusieurs problèmes apparaissent dans notre méthodologie :

* Si au départ, nous devions avoir 3 groupes, au final, seulement 2 groupes existent effectivement : les groupes CBSM et CONTROLE. Ces deux groupes sont de tailles différentes. De plus, le groupe CONTROLE réalise des exercices de relaxation.
* Des erreurs de mesures peuvent fausser nos résultats (erreurs de manipulation).De plus, nous faisons face à des individus sous médication ayant une pathologie cardiaque, les chances d'obtenir des valeurs aberantes sont grandes. 

### Durées de l'expérimentation

Les individus de l'expérience ont été exposé au programme pendant 10 semaines, sans obligations d'être présent à toute les séances, ni obligation à réaliser les exercices à faire chez soi, cela limite donc l'influence du programme sur nos patients.

Enfin, cette étude est basée sur le bénévolat. Hormis la volonté des patients, il n'y avait que peu d'obligations de poursuivre l'étude. Ainsi, nous observons une très grande absence de réponse pour les temps T2 (plusieurs mois après expérience). Nous avons aussi des patients absents lors des premières mesures, mais présent après etc.

Au final, au vu du faible de nombre de réponse pour le temps T2, nous avons décider de limiter nos analyses à T0 et T1, ne nous permettant pas de constater des résultats sur le long terme.

## Objectifs de l'analyse

Ainsi, nos objectifs sont donc les suivants :

* Corriger les valeurs aberantes de certains patients
* Déterminer un modèle de prédiction de l'amélioration de l'état d'un individu.

### Méthodes pour l'analyse

#### Imputation

TODO

#### Leave-One-Out

TODO

#### Bootstrap

A COMPLETER

Avec le peu de données que nous risquons d'avoir au final, nous avons besoin d'une méthode nous assurant de contrôler la robustesse de nos méthodes. Le bootstrap est une méthode qui se base sur le reéchantillonage avec remise. Il s'agit de considérer nos données comme la distribution de la population (pour nous, les personnes atteintes de maladie cardiaque) et donc de tirer plusieurs échantillons au sein de cette distribution.

Dans notre cas, le bootstrap est un moyen de contourner notre manque de données. Néanmoins, cette méthode dépend beaucoup de nos données de départ pour être efficace. Il faudra utiliser celle-ci avec parcimonie.

\newpage

# Premières analyses

## Données manquantes et premiers constats

Le premier problème dans notre jeu de données est la présence de données manquantes. Certaines personnes n'ont des données que concernant le temps T0 ou T1.

```{r, echo=FALSE}
# vecteur individus sans infos ) T0
vec_na_T0<-apply(X = data_physio[,num_var_T0],MARGIN = 1, FUN = function(x){sum(is.na(x))})
vec_na_T1<-apply(X = data_physio[,num_var_T1],MARGIN = 1, FUN = function(x){sum(is.na(x))})
vec_na_T0_T1<-apply(X = data_physio[,num_var_T0[1]:num_var_T1[length(num_var_T1)]],MARGIN = 1, FUN = function(x){sum(is.na(x))})
```

En effet, sur les `r nrow(data_physio)` individus du jeu de données de départ, `r sum(vec_na_T0==17)` n'ont pas de valeurs à T0, `r sum(vec_na_T1==17)` n'ont pas de données à T1 et `r sum(vec_na_T0_T1==34)` n'ont pas de données à T0 et T1.

Si nous pouvons par la suite discuter de l'intérêt de conserver des individus à qui il manque des données à T0 ou T1, il semble relativement logique de ce débarasser des individus sans données à T0 et T1 (il s'agit des personnes présentent seulement au temps T2), qui seront sans intérêt dans notre cas.

```{r, echo=FALSE}
# on modifie  les données de départ en se débarassant des personnes sans données en T0 et T1
data_physio<-data_physio[vec_na_T0_T1<=nb_var_T0,]
data_physio[is.na(data_physio$`Numéro HRV`),"Numéro HRV"]<-c(9998,9999)
data_physio<-data_physio[!(data_physio$`Numéro HRV`==87&data_physio$Groupe=="CBSM"),]
data_physio[data_physio$`Numéro HRV`==24,"Numéro HRV"]<-c(24,9997)
# Recalcul de ces vecteurs
vec_na_T0<-apply(X = data_physio[,num_var_T0],MARGIN = 1, FUN = function(x){sum(is.na(x))})
vec_na_T1<-apply(X = data_physio[,num_var_T1],MARGIN = 1, FUN = function(x){sum(is.na(x))})
```

Cela nous laisse alors avec `r nrow(data_physio)`, dont `r sum(vec_na_T0==17)` sans données à T0 et `r sum(vec_na_T1==17)` sans données à T1.

## Valeurs extrêmes

Le second problème est la présence de valeurs abérantes.

```{r, echo=FALSE}
T0_indi_sp<-apply(apply(data_physio[vec_na_T0==0,num_var_T0],2, cherche.ext),1,sum)==nb_var_T0
T1_indi_sp<-apply(apply(data_physio[vec_na_T1==0,num_var_T1],2, cherche.ext),1,sum)==nb_var_T1
```

En effet, sur les `r length(T0_indi_sp)` individus du jeu de données de départ avec des valeurs à T0, `r sum(T0_indi_sp==FALSE)` ont aun moins une valeur extrème, et sur les `r length(T1_indi_sp)` individus avec des valeurs à T1, `r sum(T1_indi_sp==FALSE)` ont au moins une valeur extrême.

# Imputation des données

Notre but premier est de remplacer les valeurs extrêmes chez nos individus. Au départ notre population est dans le même état (pas de groupe particulier à l'intérieur <-- A VERIFIER SI LE TEMPS --!>), nous pouvons donc utiliser l'ensemble des données disponible pour réaliser une imputation de données sans trop de problème.

Nous allons exclure les données manquantes de l'imputation. Imputer les valeurs manquantes au temps T1 reviendrait à prédire l'amélioration ou non de l'état de santé des patients, ce qui est certe l'objectif, mais nous nous limitons à indiquer si oui ou non il y a amélioration, nous ne souhaitons pas prédire l'ensemble des valeurs physiologique. Nous risquons alors d'influencer de façon non négligeable nos données.

Nous nous concentrerons donc seulement sur les valeurs abérantes

## Imputation à T0

```{r, echo=FALSE}
# Création du jeu de données à imputer avec des NA pour les valeurs extrêmes.

imput_T0<-cbind(data_physio[vec_na_T0==0,"Numéro HRV"],apply(data_physio[vec_na_T0==0,num_var_T0],2, FUN=function(x){
  need_replace<-!(cherche.ext(x))
  xbis<-x
  xbis[need_replace]<-NA
  return(xbis)})
)
```

Regardons le taux de valeur abérante pour chaque varialbe à T0

```{r, echo=FALSE}
# FAIRE UN JOLIE TABLEAU !!
apply(imput_T0[,-1],2,function(x){sum(is.na(x))/length(x)*100})
```
On observe que majoritairement, nous n'avons pas de de variables avec un pourcentage trop important (au dela de 10%) de valeur abérante. Nous allons donc imputer l'ensemble des variables.

### Imputation par la moyenne prévisionnelle

L'idée ici est de chercher les individus proches des individus avec des valeurs manquantes, puis de compléter ces valeurs manquantes avec la moyenne de ces individus.

```{r, echo=FALSE}
init_T0 = mice(imput_T0[,-1], maxit=0) 
meth = init_T0$method
predM = init_T0$predictorMatrix

imputed_T0 <- mice(imput_T0[,-1], method=meth, predictorMatrix=predM, m=5)
imput_T0_mean <- cbind(data_physio[vec_na_T0==0,"Numéro HRV"],complete(imputed_T0))
```

<-- AUTRES METHODES ? --!>

### Comparaison des méthodes

```{r, echo=FALSE}
summary(imput_T0[,-1])
summary(imput_T0_mean[,-1])
```

## Imputation à T1

```{r, echo=FALSE}
# Création du jeu de données à imputer avec des NA pour les valeurs extrêmes.

imput_T1<-cbind(data_physio[vec_na_T1==0,"Numéro HRV"],apply(data_physio[vec_na_T1==0,num_var_T1],2, FUN=function(x){
  need_replace<-!(cherche.ext(x))
  xbis<-x
  xbis[need_replace]<-NA
  return(xbis)})
)
```

### Imputation par la moyenne prévisionnelle

```{r, echo=FALSE}
init_T1 = mice(imput_T1[,-1], maxit=0)    
meth = init_T1$method
predM = init_T1$predictorMatrix

imputed_T1 <- mice(imput_T1[,-1], method=meth, predictorMatrix=predM, m=5)
imput_T1_mean <- cbind(data_physio[vec_na_T1==0,"Numéro HRV"],complete(imputed_T1))
```


```{r}
summary(imput_T1[,-1])
summary(imput_T1_mean[,-1])
```

<-- AUTRES METHODES ? --!>

### Test de différentes méthodes

### Création des valeurs NA dans le jeu de données complet

```{r, echo=FALSE}

T1_full<- na.omit(imput_T1[,-1])
T1P<-T1_full

#T1P valeur complete
#T1_full valeur avec données manquantes

T1_full<- prodNA(T1P, noNA = 0.05)
```
Nous avons créer un jeu de données contenant des valeurs manquantes afin de tester plus tard avec les différentes méthodes d'imputations laquelle minimise les erreurs de prédictions

### Les 5 différentes méthodes testées: (pmm, rf, sample, mean, norm)
# Predictive mean matching (pmm)

```{r, echo=FALSE}


init_T1P = mice(T1_full ,maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full, method= c("pmm"), predictorMatrix=predM,maxit=5, m=1)
imput_T1P_pmm <- complete(imputed_T1P)

R_pmm<-c()
for (i in c(1:10)){
  R_pmm[i]<-round(RMSE(imput_T1P_pmm[,i],T1P[,i]),2)
}


summary(T1P)
summary(imput_T1P_pmm)



## Unconditional mean imputation (mean)

init_T1P = mice(T1_full ,maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full, method= c("mean"), predictorMatrix=predM,maxit=5, m=1)
imput_T1P_mean <- complete(imputed_T1P)

R_mean<-c()

for (i in c(1:10)){
  R_mean[i]<-round(RMSE(imput_T1P_mean[,i],T1P[,i]),2)
}


summary(T1P)
summary(imput_T1P_mean)




# Random Forest

init_T1P = mice(T1_full ,maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full, method= c("rf"), predictorMatrix=predM,maxit=5, m=1)
imput_T1P_rf <- complete(imputed_T1P)

R_rf<-c()

for (i in c(1:10)){
  R_rf[i]<-round(RMSE(imput_T1P_rf[,i],T1P[,i]),2)
}

summary(T1P)
summary(imput_T1P_rf)





# Random sample from observed values(sample)
set.seed(10000)

init_T1P = mice(T1_full ,maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full, method= c("sample"), predictorMatrix=predM,maxit=5, m=1)
imput_T1P_sample <- complete(imputed_T1P)

R_sample<-c()

for (i in c(1:10)){
  R_sample[i]<-round(RMSE(imput_T1P_sample[,i],T1P[,i]),2)
}

summary(T1P)
summary(imput_T1P_sample)




# Bayesian linear regression (norm)

init_T1P = mice(T1_full ,maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full, method= c("norm"), predictorMatrix=predM,maxit=5, m=1)
imput_T1P_norm <- complete(imputed_T1P)


R_norm<-c()

for (i in c(1:10)){
  R_norm[i]<-round(RMSE(imput_T1P_norm[,i],T1P[,i]),2)
}

summary(T1P)
summary(imput_T1P_norm)

```


Comparaison des différentes méthodes d'imputations
```{r}
R_mse<- cbind( R_pmm, R_mean, R_rf,R_sample,R_norm)
R_compare<-cbind(R_mse, apply(R_mse, 1, min))

```

```{r}
View(R_compare)
```

Pour notre imputation de données nous avions choisi de faire un premier test sur de différentes méthodes d’imputation sur le jeu de données. En première étape il s’agit de récupérer une partie du jeu de données assez complète afin de recréer des valeurs manquantes et de comparer plus tard les résultats des différentes méthodes d’imputations que nous allons effectuer sur le jeu de données. 

La fonction MICE de la librairie mice qui renferme en elle différentes méthodes d’imputations nous servira pour ce test. De cette liste de fonction, 5 types d’imputations ont été expérimentées. Il s’agit de la Predictive mean matching PMM, la moyenne MEAN, random forest RF, Random sample for observed values SAMPLE et une dernière le Bayesian Linear Regression NORM.

Le critère de comparaison est axé sur la minimisation des erreurs de prédiction le RMSE entre les valeurs prédites par les imputations et les valeurs réelles. 
Et aussi en observant les statistiques descriptives avant et après les imputations.

Pour le choix du meilleur modèle d’imputation, choisir celle qui minimise au mieux sur l’ensemble des 10 variables et aussi en gardant un oeil sur la variable RM_SSD.

A la fin de ce test nous avons retenu 3 types d’imputations qui marchent le mieux. Le PMM et le Bayesian linear régression et la moyenne. Nous avions donc dégagé pour une première étape les trois méthodes qui seront choisies comme méthode à analyser.

La régression linéaire bayésienne est une approche de la régression linéaire dans laquelle l’analyse statistique est entreprise dans le contexte de l’inférence bayésienne.

La méthode de la moyenne utilise la moyenne obtenue sans les valeurs manquantes et les impute la même valeur à l’ensemble des valeurs manquantes

Par rapport aux méthodes standard basées sur la régression linéaire et la distribution normale, PMM produit des valeurs imputées qui ressemblent beaucoup plus à des valeurs réelles. Si la variable d'origine est asymétrique, les valeurs imputées seront également asymétriques. Si la variable d'origine est limitée par 0 et 100, les valeurs imputées seront également limitées par 0 et 100. Et si les valeurs réelles sont discrètes (comme le nombre d'enfants), les valeurs imputées seront également discrètes. En effet, les valeurs imputées sont des valeurs réelles qui sont «empruntées» à des individus disposant de données réelles. Elle fait donc moyenne des valeurs de ces observations qui le ressemblent.

Cependant en faisant une analyse des trois méthodologies d’imputations nous observons que les deux premières méthodes à savoir la bayesienne et le PMM minimise au mieux les variables. Mais pour en choisir qu'une à la fin nous analysons aussi les statistiques descriptives que fournissent ces données avant et après imputation et surtout pour la variable RMSSD en phase T1 qui servira plus tard pour la prédiction. 

La technique qui nous a facilité le choix final est la répétition de l'expérience comme une sorte de validation croisée afin de déterminer le plus fréquent des methodes d'imputation.

Au bout de 10 répétitions nous remarquons que la méthode de la moyenne prévisionnelle minimise au mieux les erreurs en considérant l'ensemble des variables et le nombre d'expérience.

Notre jeu de données sera imputée par la méthode de la moyenne prévisionnelle.

### Imputation de T1 par la regression linéaire bayesienne

```{r, echo=FALSE}
init_T1 = mice(imput_T1[,-1], maxit=0)    
meth = init_T1$method
predM = init_T1$predictorMatrix

imputed_T1 <- mice(imput_T1[,-1], method="pmm", predictorMatrix=predM, m=5)
imput_T1_pmm <- cbind(data_physio[vec_na_T1==0,"Numéro HRV"],complete(imputed_T1))
```

### Comparaison des méthodes

```{r, echo=FALSE}
summary(imput_T1[,-1])
summary(imput_T1_pmm[,-1])
```

En observant par exemple pour la variable RMSSD avant imputation et après imputation, nous obtenons une moyenne de 41,1 contre 39,9 précédemment, ce qui est acceptable par rapport à la methode utilisée et la troisième quartile qui varie de 42 à 43,82 , la médiane qui était de 26,5 passe à 27,4. Notre imputation n'a pas eu d'impact énorme sur notre jeu de données.

## Fichier final

IL SEMBLE Y AVOIR UN PROBLEME AVOIR LA PREDICTION DE LA FREQUENCE RESPIRATOIRE. POUR LE MOMENT ELLE EST ENLEVE

```{r,echo=FALSE}
# => ENTREE : imput de T0 et imput de T1

merge_data<-merge(imput_T0_mean[imput_T0_mean$`Numéro HRV` %in% imput_T1_mean$`Numéro HRV`,-18],imput_T1_mean[,-18],by="Numéro HRV")
merge_data$"progress"<-as.factor(ifelse(merge_data$T0_RMSSD_ms>merge_data$T1_RMSSD_ms,1,0))
print(table(merge_data$progress)/nrow(merge_data))

# => SORTIE : données finale avec une colonne progress pour indiquer si oui ou non il y a progré
```

# Construction de modèles

Le but est de déterminer le meilleur modèle. Pour cela, nous envisageons plusieurs méthodes. Pour chacune, nous devons en général rechercher l'hyper paramètre optimal.

## Optimisation via Leave one Out

```{r}
train_control <- trainControl(method = "LOOCV")
```

### Regression logistique

Pas sûr de la méthode sans avoir un tet après.

```{r,echo=FALSE}
m_glm<-train(progress~.,data = merge_data, method="glmStepAIC",trControl=train_control, trace=FALSE)
#print(m_glm)
print(m_glm)
```
### SVM

```{r}
m_svm_loo <- train(progress ~., data = merge_data, method="svmLinear",trControl=train_control,tuneGrid=data.frame(C=c(0.05,0.1,1:18)))
#print(m_svm_loo)
plot(m_svm_loo,main="Modèle SVM")
```

### randomForest

```{r}
m_rf_loo<-train(progress ~., data = merge_data, method="rf",trControl=train_control,tuneGrid=expand.grid(.mtry=c(2,3,6:10,12:21)))
#print(m_rf)
plot(m_rf_loo,main="Modèle RandomForest")
```

## Optimisation via Bootstrap

```{r}
train_control <- trainControl(method = "boot", number=100)
```

### Regression logistique

Pas sûr de la méthode sans avoir un tet après.

```{r,echo=FALSE}
m_glm<-train(progress~.,data = merge_data, method="glmStepAIC",trControl=train_control, trace=FALSE)
#print(m_glm)
print(m_glm)
```

### SVM

```{r}
m_svm_boot <- train(progress ~., data = merge_data, method="svmLinear",trControl=train_control,tuneGrid=data.frame(C=c(0.05,0.1,1:18)))
#print(m_svm)
plot(m_svm_boot,main="Modèle SVM")
```

On observe ici que l'optimisation du paramètre C avec le bootstrap renvoie le même résultat. On obtient des résultats équivalent. Le bootstrap n'apporte donc rien de plus que le leave one out.

### randomForest

```{r}
m_rf_boot<-train(progress ~., data = merge_data, method="rf",trControl=train_control,tuneGrid=expand.grid(.mtry=c(2,3,6:10,12:21)))
#print(m_rf)
plot(m_rf_boot,main="Modèle RandomForest")
```

Ici, l'av