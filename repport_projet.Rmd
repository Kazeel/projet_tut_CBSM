---
title: "Rapport du projet"
author: "Aimé Cazeel"
date: "3 février 2020"
output:
  html_document:
    df_print: paged
---

```{r, echo=FALSE, include=FALSE}
# Paramètre fixe
set.seed(10000)

#Importation packages

library(readxl)
library(mice)
library(MASS)
library(pROC)
library(caret)
library(kernlab)

library(klaR)
library(randomForest)
library(Metrics)
library(MLmetrics)
library(missForest)

# Fonctions

cherche.ext<-function(x,taille=2){
  sigma<-sd(x,na.rm=TRUE) # pour recalculer plusieurs fois l'écart type
  ext<-mean(x,na.rm=TRUE)+c(-taille*sigma,2*sigma) # 2 valeurs de l'intervalle
  result<-(x>=ext[1])&(x<=ext[2]) # TRUE si ok, FALSE si extrême
  return(result)
  
  # on y rentre un vecteur de données
  # souvent on considère que ce qui s'écarte de 2 écart-type de la moyenne n'est pas normal
  # mais on va laisser le choix de la taille de cet intervalle (2 ou 3 sigma ?)
}

remplace.data<-function(x,random=TRUE,ligne=NA,colonne=NA,nombre=NA){
  # permet de faire des trous dans un jeu de donnée
  data<-x
  
  if (is.na(nombre)) {
    nombre = floor(nrow(x)*ncol(x)*5/100)
  }
    
  
  if (random==TRUE) {
    nombre = floor(nrow(x)*ncol(x)*5/100)
    ligne<-sample(x = 1:nrow(x),size=nombre,replace = TRUE)
    colonne<-sample(x = 1:ncol(x),size=nombre,replace = TRUE)
  }
  for (i in 1:lengthh(ligne)) {
    data[ligne[i],colonne[i]]<-NA
  }
  
  return(list("data"=data,"ligne"=ligne,"colonne"=colonne))
}

```

\newpage

# Résumé

Le CBSM ou Cognitive Behavioral Stress Management est un programme de gestion du stress qui mélange des exercices de relaxation, de restructuration cognitive et de dynamique de groupe.Si ce programme étudié principalement aux Etats-Unis s'avère efficace sur des maladies comme le cancer du sein ou le VIH, il n'existe cependant que peu d'études sur l'application du programme CBSM sur des patients atteints de maladies cardio-vasculaires et de son effet sur le stress, l'anxiété et les pensées intrusives.

Ainsi, l'objectif de ce document est d'étudier l'efficacité de ce programme auprès de patients atteints de maladies cardio-vasculaires. Pour cela, les patients ont été séparés en 2 groupes, un groupe témoin et un groupe participant au programme CBSM. Des mesures physiologiques ont étés relevés avant et après l'application du programme.

Une étude ultérieur ayant mis en valeur l'efficacité du programme concernant l'amélioration du stress perçu et de l'anxiété, nous cherchons ici à étudier l'efficacité du programme sur le stress ressenti.

<--- DO TO COMPLETER AVEC CONCLUSION  ---!>

\newpage

# Introduction

## Etat des lieux

Les maladies cardiovasculaires sont un ensemble de troubles affectant le coeur et les vaisseaux sanguins. Première cause de mortalité dans le monde selon l'OMS, elles nécessitent souvent une prise en charge lourde comprenant soutien psychologique et médicaments. Ainsi, il est important de trouver des solutions efficaces pour aider les personnes exposées à ces maladies.

Si l'alimentation et le tabagisme sont des facteurs aggravant connus, de nombreuses études mettent en évidence l'existence d'un lien entre stress et maladies cardio-vasculaires. Ainsi, proposer des solutions agissant sur le stress et ne nécessitant pas une prise en charge lourde ou médicamenteuse peut permettre de soulager les personnes atteintes de problèmes cardiovasculaires.

Or, il existe de nombreuses méthodes pour faciliter la gestion du stress, dont le programme CBSM.

## CBSM ou Cognitive Behavioral Stress Management

Le CBSM est un programme de gestion du stress qui mélange des exercices de relaxation, de restructuration cognitive et de dynamique de groupe.L'objectif est de permettre aux patients d'avoir accès à des connaisances sur eux-même, sur le stress et son impact, et sur les réactions psychologiques qu'il peut susciter. Il est constitué de plusieurs séances en groupe ainsi que d'exercices à réaliser chez soi.

Si ce programme étudié principalement aux Etats-Unis s'avére efficace sur des maladies comme le cancer du sein ou le VIH, il n'existe cependant que peu d'études sur l'application du programme CBSM sur des patients atteints de maladies cardio-vasculaires et de son effet sur le stress, l'anxiété et les pensées intrusives.

## Expérience

Ainsi en 2016 une expérience a été réalisé sur des patients atteints de pathologies cardiaques. Ces patients ont suivi le programme CBSM et ont répondus à des questionnaires afin d'évaluer leurs états psychologiques. De plus des relevés physiologiques ont aussi été réalisés. Les questionnaires doivent permettre d'évaluer le ressenti des patients par rapport au stress, tandis que les relevés physiologique permettent d'évaluer l'impact physique des interventions.

# Objectif

Ce document fait suite au travail rédigé par Franck D'ALESSANDRO mettant en avant l'efficacité du programme CBSM sur la diminution du stress perçu par les patients ainsi que leur anxiété, ainsi que le travail de Aimé CAZEEL confirmant une partie de ces résultats.

Le but de cette étude est donc d'analyser l'influence  du programme sur le stress "physique" des patients (que l'on distinguera du stress perçu).

```{r, echo=FALSE, results='hide',warning=FALSE}
# Importation des données

#data_physio <- read_excel("./data/datas_physio_cbsm.xlsx",sheet=2)
data_physio <- read_excel("/Users/khadija/Desktop/Stage_HRV/CBSM cardio-data/Fichiers_CBSM_data_Excel/datas_physio_cbsm.xlsx",sheet=2)
# Formattage des noms des colonnes

# PHYSIO
##Renommage
colnames(data_physio)[5:21]<-c("T0_Mean_RR_ms","T0_STD_RR_ms","T0_Mean_HR_1_min","T0_STD_HR_1_min","T0_RMSSD_ms",
"T0_VLF_ms2","T0_LF_ms2","T0_HF_ms2","T0_VLF_pourcent","T0_LF_pourcent","T0_HF_pourcent","T0_LF_nu",
"T0_HF_nu","T0_Total_power_ms2","T0_LF_HF_ratio","T0_EDR_Hz","T0_Frequence_Respiratoire")

colnames(data_physio)[22:40]<-c("Espace_1","Espace_2","T1_Mean_RR_ms","T1_STD_RR_ms","T1_Mean_HR_1_min","T1_STD_HR_1_min","T1_RMSSD_ms",
"T1_VLF_ms2","T1_LF_ms2","T1_HF_ms2","T1_VLF_pourcent","T1_LF_pourcent","T1_HF_pourcent","T1_LF_nu",
"T1_HF_nu","T1_Total_power_ms2","T1_LF_HF_ratio","T1_EDR_Hz","T1_Frequence_Respiratoire")

colnames(data_physio)[41:57]<-c("T2_Mean_RR_ms","T2_STD_RR_ms","T2_Mean_HR_1_min","T2_STD_HR_1_min","T2_RMSSD_ms",
"T2_VLF_ms2","T2_LF_ms2","T2_HF_ms2","T2_VLF_pourcent","T2_LF_pourcent","T2_HF_pourcent","T2_LF_nu",
"T2_HF_nu","T2_Total_power_ms2","T2_LF_HF_ratio","T2_EDR_Hz","T2_Frequence_Respiratoire")

##suppression des colonnes espaces
data_physio<-data_physio[,!colnames(data_physio)%in%c("Espace_1","Espace_2")]
data_physio<-data_physio[,!colnames(data_physio)%in%c("T0_VLF_pourcent","T0_LF_pourcent","T0_HF_pourcent","T0_LF_nu","T0_HF_nu","T0_LF_HF_ratio","T0_EDR_Hz","T1_VLF_pourcent","T1_LF_pourcent","T1_HF_pourcent","T1_LF_nu","T1_HF_nu","T1_LF_HF_ratio","T1_EDR_Hz","T2_Mean_RR_ms","T2_STD_RR_ms","T2_Mean_HR_1_min","T2_STD_HR_1_min","T2_RMSSD_ms",
"T2_VLF_ms2","T2_LF_ms2","T2_HF_ms2","T2_VLF_pourcent","T2_LF_pourcent","T2_HF_pourcent","T2_LF_nu",
"T2_HF_nu","T2_Total_power_ms2","T2_LF_HF_ratio","T2_EDR_Hz","T2_Frequence_Respiratoire")]

num_var_T0<-5:14
num_var_T1<-15:24
nb_var_T0<-length(num_var_T0)
nb_var_T1<-length(num_var_T1)
```

\newpage

# Approche du problème

## Participants

Au départ, l'expérience porte sur 150 participants ayant développés une maladie cardiaque. 50 personnes participent au programme CBSM, 50 personnes participent à des séances la relaxation et 50 personnes sont des individus "contrôle" ne suivant pas de programme particulier (hormis les soins). Ces personnes proviennent de différent lieux dans l'aglomération de Grenoble :

* Service de réadaptation cardiaque de l'hôpital Sud (Echirolles)
* Institut cardio-vascualire du groupe hospitalier mutualiste de Grenoble
* Réseau des pathologies vasculaires GRANTED à Saint-Martin-d'Hères
* Service de cardiologie du CHU La Tronche
* Service de diabétologie du CHU La Tronche

Les patients sont recrutés par les équipes soignantes, les personnes acceptant de participés sont placés aléatoirement dans l'un des 3 groupes.

## Méthodes d'expérimentation

Le programme CBSM est constitué de plusieurs séances (2h par semaine) avec en plus des excercices à réaliser chez soi. Après l'ensemble des séances, les patients sont invités à répondre à des questionnaires mesurant leur perception du stress puis des mesure physiologiques sont prises. Ces mesures sont prises avec un module BIOPAC MP 150 qui va permettre de relever plusieurs variables.

Les mesures et les réponses aux questionnaires sont pris à différents moments :

* T0 : avant le début des séances CBSM
* T1 : à la fin des 10 semaines d'interventions
* T2 : 6 mois après l'intervention

### Mesure physiologique : HRV ou  Heart Rate Variability

Les recherches en psychophysiologie intègrent de plus en plus d'étude sur la variabilité du rythme cardiaque (HRV). En effet, il existe un lien entre le système nerveux parasympathique (lié à la régulation cardiaque) et de nombreux phénomènes psychophysiologique. Le HRV est d'ailleurs utilisé pour prédire les risques de mortalité provenant de cause mental ou physique.

Un relevé du HRV est simple à mettre en place et sans douleur, d'où son utilisation répandue. Parmis les nombreuses variables étudiables, celles d'intérêts sont :

* RMSSD (Root Mean Square of Succesive differences) dont les variations sont dépendantes du tonus vagal (activité du nerf vague, composant du sytème parasympathique contrôlant les activités involontaires des organes).
* HF (High Frenquencies) dont les variations proviennent aussi du tonus vagal mais peuvent être influencé par la respiration.
* LF (Low Frequencies) ainsi que le rapport LF/HF, dont les variations dépendent de divers éléments dont le système sympathique (responsable du rythme cardiaque mais aussi de la contraction des muscles lisses) et le tonus vagal.

Bien que facile à relever, le HRV est sujet à des erreurs de mesures ou à des modifications de celui-ci dû à des facteurs externes pouvant le rendre difficile à étudier (caféine etc...)

Dans les études statistiques, le HRV est très souvent utlisé comme une variable les régressions ou les corrélations, permettant souvent de distinguer des groupes selons d'autres critères (comme des différences individuelles). Parfois, le HRV peut être considéré comme une variable dépendante en créant 2 groupes séparés par la médiane. A ce moment, on suppose que le HRV illustre des particularité individuelles (on sait par exemple que le controle vagal est partiellement héritable, ce qui peut en faire une information propre à chaque individus et non dépendantes de variables externes).
 
Concernant la distribution des variables liées au HRV, la question de la normalité des variables est discutée. Mais des études tendent à observer une non normalité de la distribution de ces variables. La transformation logarithmique est alors une procédure courante pour remédier à ce problème.

## Limitations

### Erreurs

Plusieurs problèmes apparaissent dans notre méthodologie :

* Si au départ, nous devions avoir 3 groupes, au final, seulement 2 groupes existent effectivement : les groupes CBSM et CONTROLE. Ces deux groupes sont de tailles différentes. De plus, le groupe CONTROLE réalise des exercices de relaxation.
* Des erreurs de mesures peuvent fausser nos résultats (erreurs de manipulation).De plus, nous faisons face à des individus sous médication ayant une pathologie cardiaque, les chances d'obtenir des valeurs aberantes sont grandes. 

### Durées de l'expérimentation

Les individus de l'expérience ont été exposé au programme pendant 10 semaines, sans obligations d'être présent à toute les séances, ni obligation à réaliser les exercices à faire chez soi, cela limite donc l'influence du programme sur nos patients.

Enfin, cette étude est basée sur le bénévolat. Hormis la volonté des patients, il n'y avait que peu d'obligations de poursuivre l'étude. Ainsi, nous observons une très grande absence de réponse pour les temps T2 (plusieurs mois après expérience). Nous avons aussi des patients absents lors des premières mesures, mais présent après etc.

Au final, au vu du faible de nombre de réponse pour le temps T2, nous avons décider de limiter nos analyses à T0 et T1, ne nous permettant pas de constater des résultats sur le long terme.

## Objectifs de l'analyse

Ainsi, nos objectifs sont donc les suivants :

* Corriger les valeurs aberantes de certains patients
* Déterminer un modèle de prédiction de l'amélioration de l'état d'un individu.

### Méthodes pour l'analyse

#### Imputation

TODO

#### SVM

#### Random Forest

A COMPLETER

Les forêts d'arbres de décisions sont des méthodes d'apprentissage basé sur les concepts de bagging (ou bootstrap) et de sous-espaces aléatoire. Le principe est d'effectuer un apprentissage d'arbre de décision sur des sous-ensembles de données.

L'arbre de décision est une méthode d'apprentissage qui cherche à découper nos données en sous-ensemble par des critères maxisimisant (selon les algorithmes) la différence entre les sous-ensembles. On sépare nos données selon une variable puis l'on réintère ce processus pour chaque sous-groupe.

Ces méthodes sont assez courantes parmis les méthodes d'apprentissage supervisée.

#### Leave-One-Out

TODO

#### Bootstrap

A COMPLETER

Avec le peu de données que nous risquons d'avoir au final, nous avons besoin d'une méthode nous assurant de contrôler la robustesse de nos méthodes. Le bootstrap est une méthode qui se base sur le reéchantillonage avec remise. Il s'agit de considérer nos données comme la distribution de la population (pour nous, les personnes atteintes de maladie cardiaque) et donc de tirer plusieurs échantillons au sein de cette distribution.

Dans notre cas, le bootstrap est un moyen de contourner notre manque de données. Néanmoins, cette méthode dépend beaucoup de nos données de départ pour être efficace. Il faudra utiliser celle-ci avec parcimonie.

\newpage

# Premières analyses

## Données manquantes et premiers constats

Le premier problème dans notre jeu de données est la présence de données manquantes. Certaines personnes n'ont des données que concernant le temps T0 ou T1.

```{r, echo=FALSE}
# vecteur individus sans infos ) T0
vec_na_T0<-apply(X = data_physio[,num_var_T0],MARGIN = 1, FUN = function(x){sum(is.na(x))})
vec_na_T1<-apply(X = data_physio[,num_var_T1],MARGIN = 1, FUN = function(x){sum(is.na(x))})
vec_na_T0_T1<-apply(X = data_physio[,num_var_T0[1]:num_var_T1[length(num_var_T1)]],MARGIN = 1, FUN = function(x){sum(is.na(x))})
```

En effet, sur les `r nrow(data_physio)` individus du jeu de données de départ, `r sum(vec_na_T0==17)` n'ont pas de valeurs à T0, `r sum(vec_na_T1==17)` n'ont pas de données à T1 et `r sum(vec_na_T0_T1==34)` n'ont pas de données à T0 et T1.

Si nous pouvons par la suite discuter de l'intérêt de conserver des individus à qui il manque des données à T0 ou T1, il semble relativement logique de ce débarasser des individus sans données à T0 et T1 (il s'agit des personnes présentent seulement au temps T2), qui seront sans intérêt dans notre cas.

```{r, echo=FALSE}
# on modifie  les données de départ en se débarassant des personnes sans données en T0 et T1
data_physio<-data_physio[vec_na_T0_T1<=nb_var_T0,]
data_physio[is.na(data_physio$`Numéro HRV`),"Numéro HRV"]<-c(9998,9999)
data_physio<-data_physio[!(data_physio$`Numéro HRV`==87&data_physio$Groupe=="CBSM"),]
data_physio[data_physio$`Numéro HRV`==24,"Numéro HRV"]<-c(24,9997)
# Recalcul de ces vecteurs
vec_na_T0<-apply(X = data_physio[,num_var_T0],MARGIN = 1, FUN = function(x){sum(is.na(x))})
vec_na_T1<-apply(X = data_physio[,num_var_T1],MARGIN = 1, FUN = function(x){sum(is.na(x))})
```

Cela nous laisse alors avec `r nrow(data_physio)`, dont `r sum(vec_na_T0==17)` sans données à T0 et `r sum(vec_na_T1==17)` sans données à T1.

## Valeurs extrêmes

Le second problème est la présence de valeurs abérantes.

```{r, echo=FALSE}
T0_indi_sp<-apply(apply(data_physio[vec_na_T0==0,num_var_T0],2, cherche.ext),1,sum)==nb_var_T0
T1_indi_sp<-apply(apply(data_physio[vec_na_T1==0,num_var_T1],2, cherche.ext),1,sum)==nb_var_T1
```

En effet, sur les `r length(T0_indi_sp)` individus du jeu de données de départ avec des valeurs à T0, `r sum(T0_indi_sp==FALSE)` ont aun moins une valeur extrème, et sur les `r length(T1_indi_sp)` individus avec des valeurs à T1, `r sum(T1_indi_sp==FALSE)` ont au moins une valeur extrême.

# Imputation des données

Notre but premier est de remplacer les valeurs extrêmes chez nos individus. Au départ notre population est dans le même état (pas de groupe particulier à l'intérieur <-- A VERIFIER SI LE TEMPS --!>), nous pouvons donc utiliser l'ensemble des données disponible pour réaliser une imputation de données sans trop de problème.

Nous allons exclure les données manquantes de l'imputation. Imputer les valeurs manquantes au temps T1 reviendrait à prédire l'amélioration ou non de l'état de santé des patients, ce qui est certe l'objectif, mais nous nous limitons à indiquer si oui ou non il y a amélioration, nous ne souhaitons pas prédire l'ensemble des valeurs physiologique. Nous risquons alors d'influencer de façon non négligeable nos données.

Nous nous concentrerons donc seulement sur les valeurs abérantes

## Imputation à T0

```{r, echo=FALSE}
# Création du jeu de données à imputer avec des NA pour les valeurs extrêmes.

imput_T0<-cbind(data_physio[vec_na_T0==0,"Numéro HRV"],apply(data_physio[vec_na_T0==0,num_var_T0],2, FUN=function(x){
  need_replace<-!(cherche.ext(x))
  xbis<-x
  xbis[need_replace]<-NA
  return(xbis)})
)
```

  En T0, nous avons environ 81 observations et 10 variables avec 35 valeurs manquantes. Vu la taille de nos données, nous ne pouvons pas nous permettre de supprimer ces valeurs manquantes, donc nous allons procéder à une imputation.

###Répartition des NA par variables
Regardons le taux de valeurs abérantes pour chaque varialbe à T0:
```{r}
imput_T0=imput_T0[,-1]
sapply(imput_T0, function(x) sum(is.na(x)))
```

```{r}

#plot the missing values
#nhanes_miss = aggr(imput_T0, col=mdc(1:2), numbers=TRUE, sortVars=TRUE, labels=names(imput_T0), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
```
On observe que de manière générale, les variables n'ont pas un taux trop important de valeurs abérantes. Nous allons donc imputer l'ensemble des variables.
Considérons notre tableau de données sans les NA, puis créons artificiellement et aléatoirement 5% de valeurs manquantes.
```{r}
set.seed(10000)
#dim(imput_T0)
#sum(is.na(imput_T0))
tab=na.omit(imput_T0)
tabb <- prodNA (tab, noNA = 0.05)

```

Avant d'imputer, comparons tout d'abord plusieurs techniques d'imputations pour voir laquelle est la meilleure. Nous allons utiliser le package MICE.
MICE (Mutivariate Imputation via Chained Equations) est un package qui permet d'utiliser plusieurs techniques d'imputations pour traiter les données manquantes.

Pour notre imputation de données nous avions choisi de faire un premier test sur de différentes méthodes d’imputation sur le jeu de données. En première étape il s’agit de récupérer une partie du jeu de données assez complète afin de recréer des valeurs manquantes et de comparer plus tard les résultats des différentes méthodes d’imputations que nous allons effectuer sur le jeu de données. 

La fonction MICE de la librairie mice qui renferme en elle différentes méthodes d’imputations nous servira pour ce test. De cette liste de fonction, 5 types d’imputations ont été expérimentées. Il s’agit de la Predictive mean matching PMM, la moyenne MEAN, random forest RF, Random sample for observed values SAMPLE et une dernière le Bayesian Linear Regression NORM.

Le critère de comparaison est axé sur la minimisation des erreurs de prédiction le RMSE entre les valeurs prédites par les imputations et les valeurs réelles. 
Et aussi en observant les statistiques descriptives avant et après les imputations.

Pour le choix du meilleur modèle d’imputation, choisir celle qui minimise au mieux sur l’ensemble des 10 variables et aussi en gardant un oeil sur la variable RM_SSD.

A la fin de ce test nous avons retenu 3 types d’imputations qui marchent le mieux. Le PMM et le Bayesian linear régression et la moyenne. Nous avions donc dégagé pour une première étape les trois méthodes qui seront choisies comme méthode à analyser.

La régression linéaire bayésienne est une approche de la régression linéaire dans laquelle l’analyse statistique est entreprise dans le contexte de l’inférence bayésienne.

La méthode de la moyenne utilise la moyenne obtenue sans les valeurs manquantes et les impute la même valeur à l’ensemble des valeurs manquantes

Par rapport aux méthodes standard basées sur la régression linéaire et la distribution normale, PMM produit des valeurs imputées qui ressemblent beaucoup plus à des valeurs réelles. Si la variable d'origine est asymétrique, les valeurs imputées seront également asymétriques. Si la variable d'origine est limitée par 0 et 100, les valeurs imputées seront également limitées par 0 et 100. Et si les valeurs réelles sont discrètes (comme le nombre d'enfants), les valeurs imputées seront également discrètes. En effet, les valeurs imputées sont des valeurs réelles qui sont «empruntées» à des individus disposant de données réelles. Elle fait donc moyenne des valeurs de ces observations qui le ressemblent.


###Méthode par la Moyenne (Mean)
Nous avons utilisé 3 paramètres:
- m= le nombre imputation par NA
- maxit= nombre d'itérations
- method= méthode utilisée
```{r}
#dim(tab)
imputed_Data_mean <- mice(tabb, m=1, maxit = 5, method = c('mean'), seed = 500)
```

Voici un summary de l'imputation:
```{r}
summary(imputed_Data_mean)
densityplot(imputed_Data_mean)
```

En regardant les fonctions de densité, nous remarquons que, pour la plupart des variables, les fonctions de densités des valeurs imputées(en rouge) sont assez différentes des vraies valeurs(en bleu).
Après imputation, nous allons calculer le MAE, RMSE, et MAPE afin de voir l' accuracy de chaque méthode d'imputation.

######### A COMPLETER DEFINITION ET FORMULES
DEFINITION MAE MRMSE ET MAPE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
RMSE (Root Mean Squared Error) and MAE(Mean Absolute Error), represent two different measures of the model prediction error. The lower the RMSE and the MAE, the better the model. 
Voici les résultats obtenus après imputation par la moyenne:
#########

```{r}
imput_mean <- complete(imputed_Data_mean)

mae_mean<-c()
rmse_mean<-c()
mape_mean<-c()
for (i in c(1:10)){
  #mae_mean[i]<-round(mae(imput_mean[,i],tab[,i]),2)
   mae_mean[i]<-round(mae(tab[,i],imput_mean[,i]),2)

  #rmse_mean[i]<-round(rmse(imput_mean[,i],tab[,i]),2)
      rmse_mean[i]<-round(rmse(tab[,i],imput_mean[,i]),2)

  #mape_mean[i]<-round(mape(imput_mean[,i],tab[,i]),2)
    mape_mean[i]<-round(mape(tab[,i],imput_mean[,i]),2)

}
Accuracy_mean<-cbind (mae=mae_mean, rmse=rmse_mean, mape=mape_mean)
Accuracy_mean
```


###Méthode par Predictive Mean Matching (pmm)
pmm=? à definir
```{r}
imputed_Data_pmm <- mice(tabb, m=1, maxit = 5, method = 'pmm', seed = 500)
summary(imputed_Data_pmm)
densityplot(imputed_Data_pmm)

```


```{r}
imput_pmm <- complete(imputed_Data_pmm)
mae_pmm<-c()
rmse_pmm<-c()
mape_pmm<-c()
for (i in c(1:10)){
    mae_pmm[i]<-round(mae(tab[,i],imput_pmm[,i]),2)
    rmse_pmm[i]<-round(rmse(tab[,i],imput_pmm[,i]),2)
    mape_pmm[i]<-round(mape(tab[,i],imput_pmm[,i]),2)

}
Accuracy_pmm<-cbind (mae=mae_pmm, rmse=rmse_pmm, mape=mape_pmm)
Accuracy_pmm
```

###Méthode par Random Forest (rf)

```{r}
imputed_Data_rf <- mice(tabb, m=1, maxit = 5, method = 'rf', seed = 500)
summary(imputed_Data_rf)
densityplot(imputed_Data_rf)

```


```{r}
imput_rf <- complete(imputed_Data_rf)
mae_rf<-c()
rmse_rf<-c()
mape_rf<-c()
for (i in c(1:10)){
    mae_rf[i]<-round(mae(tab[,i],imput_rf[,i]),2)
    rmse_rf[i]<-round(rmse(tab[,i],imput_rf[,i]),2)
    mape_rf[i]<-round(mape(tab[,i],imput_rf[,i]),2)

}
Accuracy_rf<-cbind (mae=mae_rf, rmse=rmse_rf, mape=mape_rf)
Accuracy_rf
```

###Méthode par Classification and Regression trees (cart)

```{r}
imputed_Data_cart <- mice(tabb, m=1, maxit = 5, method = 'cart', seed = 500)
summary(imputed_Data_cart)
densityplot(imputed_Data_cart)

```

```{r}
imput_cart <- complete(imputed_Data_cart)
mae_cart<-c()
rmse_cart<-c()
mape_cart<-c()
for (i in c(1:10)){
    mae_cart[i]<-round(mae(tab[,i],imput_cart[,i]),2)
    rmse_cart[i]<-round(rmse(tab[,i],imput_cart[,i]),2)
    mape_cart[i]<-round(mape(tab[,i],imput_cart[,i]),2)

}
Accuracy_cart<-cbind (mae=mae_cart, rmse=rmse_cart, mape=mape_cart)
Accuracy_cart
```

###Méthode par Bayesian linear regression  (norm)
```{r}
imputed_Data_norm <- mice(tabb, m=1, maxit = 5, method = 'norm', seed = 500)
summary(imputed_Data_norm)
densityplot(imputed_Data_norm)
```

```{r}
imput_norm <- complete(imputed_Data_norm)

mae_norm<-c()
rmse_norm<-c()
mape_norm<-c()
for (i in c(1:10)){
    mae_norm[i]<-round(mae(tab[,i],imput_norm[,i]),2)
    rmse_norm[i]<-round(rmse(tab[,i],imput_norm[,i]),2)
    mape_norm[i]<-round(mape(tab[,i],imput_norm[,i]),2)

}
Accuracy_norm<-cbind (mae=mae_norm, rmse=rmse_norm, mape=mape_norm)
Accuracy_norm

```

###Comparaison des résultats
```{r}

AccurMAE=cbind.data.frame(Accuracy_mean[,1],Accuracy_pmm[,1],Accuracy_rf[,1],Accuracy_cart[,1],Accuracy_norm[,1])
AccurRMSE=cbind.data.frame(Accuracy_mean[,2],Accuracy_pmm[,2],Accuracy_rf[,2],Accuracy_cart[,2],Accuracy_norm[,2])
AccurMAPE=cbind.data.frame(Accuracy_mean[,3],Accuracy_pmm[,3],Accuracy_rf[,3],Accuracy_cart[,3],Accuracy_norm[,3])

AccurRMSE

Accuracy<-cbind(Methods=c("Mean","pmm","rf","cart","norm"),
                         rbind.data.frame(Accuracy_mean,Accuracy_pmm,Accuracy_rf,
                         Accuracy_cart,Accuracy_norm))
library (ggplot2)


#Scatter plot  des MASE
#ggplot(data=Accuracy, aes(x=Methods, y=mape)) +
#geom_point()

#Scatter plot  des MAE
#ggplot(data=Accuracy, aes(x=Methods, y=mae)) +
#geom_point()

#Scatter plot  des RMSE
ggplot(data=Accuracy, aes(x=Methods, y=rmse)) +
geom_point()
#A partir de ce graphique, nous voyons que ce sont les méthodes norm et pmm qui donnent les meilleures résultats.

```

En faisant une analyse des cinq méthodologies d’imputations nous observons que les deux premières méthodes à savoir la regression linéaire bayesienne(norm) et le pmm minimise au mieux les variables. Mais pour en choisir qu'une à la fin nous analysons aussi les statistiques descriptives que fournissent ces données avant et après imputation et surtout pour la variable RMSSD en phase T1 qui servira plus tard pour la prédiction. 

###Comparaison des statistiques descriptives des méthodes
```{r}
summary(tab)
summary(imput_norm)

summary(tab)
summary(imput_pmm)

```

Nous allons donc imputer par le pmm!

## Imputation à T1

```{r, echo=FALSE}
# Création du jeu de données à imputer avec des NA pour les valeurs extrêmes.

imput_T1<-cbind(data_physio[vec_na_T1==0,"Numéro HRV"],apply(data_physio[vec_na_T1==0,num_var_T1],2, FUN=function(x){
  need_replace<-!(cherche.ext(x))
  xbis<-x
  xbis[need_replace]<-NA
  return(xbis)})
)
```


### Création des valeurs NA dans le jeu de données complet

```{r, echo=FALSE}

T1_full<- na.omit(imput_T1[,-1])
T1P<-T1_full

#T1P valeur complete
#T1_full valeur avec données manquantes

T1_full<- prodNA(T1P, noNA = 0.05)
```
Nous avons créer un jeu de données contenant des valeurs manquantes afin de tester plus tard avec les différentes méthodes d'imputations laquelle minimise les erreurs de prédictions

### Les 5 différentes méthodes testées: (pmm, rf, sample, mean, norm)

```{r, echo=FALSE}

set.seed(10000)

init_T1P = mice(T1_full ,maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full, method= c("pmm"), predictorMatrix=predM,maxit=5, m=1)
imput_T1P_pmm <- complete(imputed_T1P)

R_pmm<-c()
for (i in c(1:10)){
  R_pmm[i]<-round(RMSE(imput_T1P_pmm[,i],T1P[,i]),2)
}

## Unconditional mean imputation (mean)

init_T1P = mice(T1_full ,maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full, method= c("mean"), predictorMatrix=predM,maxit=5, m=1)
imput_T1P_mean <- complete(imputed_T1P)

R_mean<-c()

for (i in c(1:10)){
  R_mean[i]<-round(RMSE(imput_T1P_mean[,i],T1P[,i]),2)
}


# Random Forest

init_T1P = mice(T1_full ,maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full, method= c("rf"), predictorMatrix=predM,maxit=5, m=1)
imput_T1P_rf <- complete(imputed_T1P)

R_rf<-c()

for (i in c(1:10)){
  R_rf[i]<-round(RMSE(imput_T1P_rf[,i],T1P[,i]),2)
}


# Random sample from observed values(sample)

init_T1P = mice(T1_full ,maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full, method= c("sample"), predictorMatrix=predM,maxit=5, m=1)
imput_T1P_sample <- complete(imputed_T1P)

R_sample<-c()

for (i in c(1:10)){
  R_sample[i]<-round(RMSE(imput_T1P_sample[,i],T1P[,i]),2)
}


# Bayesian linear regression (norm)

init_T1P = mice(T1_full ,maxit=5) 
predM = init_T1P$predictorMatrix
imputed_T1P <- mice(T1_full, method= c("norm"), predictorMatrix=predM,maxit=5, m=1)
imput_T1P_norm <- complete(imputed_T1P)


R_norm<-c()

for (i in c(1:10)){
  R_norm[i]<-round(RMSE(imput_T1P_norm[,i],T1P[,i]),2)
}

```


###Comparaison des différentes méthodes d'imputations
```{r}
R_mse<- cbind( R_pmm, R_mean, R_rf,R_sample,R_norm)
R_compare<-cbind(R_mse, apply(R_mse, 1, min))
R_compare
```

En faisant une analyse des cinq méthodologies d’imputations nous observons que les deux premières méthodes à savoir la regression linéaire bayesienne(norm) et le pmm minimise au mieux les variables. Mais pour en choisir qu'une à la fin nous analysons aussi les statistiques descriptives que fournissent ces données avant et après imputation et surtout pour la variable RMSSD en phase T1 qui servira plus tard pour la prédiction. 

###Comparaison des statistiques descriptives des méthodes
```{r}
summary(T1P)
summary(imput_T1P_norm)

summary(T1P)
summary(imput_T1P_pmm)

```

Notre jeu de données sera imputée par la méthode de la moyenne prévisionnelle.

### Imputation de T1 par la regression linéaire bayesienne

```{r, echo=FALSE}
init_T1 = mice(imput_T1[,-1], maxit=0)    
meth = init_T1$method
predM = init_T1$predictorMatrix

imputed_T1 <- mice(imput_T1[,-1], method="pmm", predictorMatrix=predM, m=5)
imput_T1_pmm <- cbind(data_physio[vec_na_T1==0,"Numéro HRV"],complete(imputed_T1))
```

### Comparaison des méthodes

```{r, echo=FALSE}
summary(imput_T1[,-1])
summary(imput_T1_pmm[,-1])
```

En observant par exemple pour la variable RMSSD avant imputation et après imputation, nous obtenons une moyenne de 41,1 contre 39,9 précédemment, ce qui est acceptable par rapport à la methode utilisée et la troisième quartile qui varie de 42 à 43,82 , la médiane qui était de 26,5 passe à 27,4. Notre imputation n'a pas eu d'impact énorme sur notre jeu de données.

## Fichier final

```{r cars}

imput_T0<-cbind(data_physio[vec_na_T0==0,"Numéro HRV"],apply(data_physio[vec_na_T0==0,num_var_T0],2, FUN=function(x){
  need_replace<-!(cherche.ext(x))
  xbis<-x
  xbis[need_replace]<-NA
  return(xbis)})
)

imput_T1<-cbind(data_physio[vec_na_T1==0,"Numéro HRV"],apply(data_physio[vec_na_T1==0,num_var_T1],2, FUN=function(x){
  need_replace<-!(cherche.ext(x))
  xbis<-x
  xbis[need_replace]<-NA
  return(xbis)})
)

library(dplyr)
pp=imput_T0 %>% inner_join(imput_T1, by = "Numéro HRV")
ppp=pp[,-1]

#View(pp)

imp_data <- mice(ppp, m=1, maxit = 5, method = 'pmm', seed = 500)
densityplot(imp_data)
final <- complete(imp_data)
NuméroHRV=pp[,1]
final=cbind(NuméroHRV,final)
#View(final)

```

### Comparaison avant et après imputation

```{r, echo=FALSE}
print("RMSSD Avant Imputation")
summary(pp[,6])
print("#####################################################################")
print("#####################################################################")
print("RMSSD Après Imputation")
summary(final[,16])
```

```{r,echo=FALSE}
T0=final[,c(1:11)]
T1=final[,c(1,12:21)]
final=cbind(NuméroHRV,final) #fichier qui combine les T0 et T1

# => ENTREE : imput de T0 et imput de T1

#merge_data<-merge(T0[T0$`NuméroHRV` %in% T1$`NuméroHRV`,-18],T1[,-18],by="NuméroHRV")
merge_data=final
merge_data$"progress"<-as.factor(ifelse(merge_data$T0_RMSSD_ms>merge_data$T1_RMSSD_ms,1,0))

print(table(merge_data$progress)/nrow(merge_data))

# => SORTIE : données finale avec une colonne progress pour indiquer si oui ou non il y a progré
```
Nous avons 50% de progrès.

#Boostrap: comparaison de moyenne

A COMMENTER!!!!
```{r}
#H0:T0>T1

x=T0$T0_RMSSD_ms
y=T1$T1_RMSSD_ms
n=length(x)
m=length(y)

wilcox=c()
M0=c()
M1=c()
B=200
wilcox=numeric(B)
M0=numeric(B)
M1=numeric(B)

for(b in 1:B){
ind1 = sample(c(1:n),n, replace = T)
ind2 = sample(c(1:m),m, replace = T)

x1=x[ind1]
y1=y[ind2]
wilcox[b] = wilcox.test(x1,y1,alternative = "greater")$p.value
M0[b]=mean(x1)
M1[b]=mean(y1)
}

help("wilcox.test")
print("pval")
wilcox
print("M0")
M0
print("M1")
M1
pval_boot=mean(wilcox)
M0_boot=mean(M0)
M1_boot=mean(M1)

print("pval"); pval_boot; print("M0"); M0_boot; print("M1"); M1_boot;
```

# Construction de modèles

Le but est de déterminer le meilleur modèle. Pour cela, nous envisageons plusieurs méthodes. Pour chacune, nous devons en général rechercher l'hyper paramètre optimal.

## Optimisation via Leave one Out

```{r}
train_control <- trainControl(method = "LOOCV")
```

### Regression logistique

Pas sûr de la méthode sans avoir un tet après.

```{r,echo=FALSE}
m_glm<-train(progress~.,data = merge_data, method="glmStepAIC",trControl=train_control, trace=FALSE)
#print(m_glm)
print(m_glm)
```
### SVM

```{r}
m_svm_loo <- train(progress ~., data = merge_data, method="svmLinear",trControl=train_control,tuneGrid=data.frame(C=c(0.05,0.1,1:18)))
#print(m_svm_loo)
plot(m_svm_loo,main="Modèle SVM")
```

### randomForest

```{r}
m_rf_loo<-train(progress ~., data = merge_data, method="rf",trControl=train_control,tuneGrid=expand.grid(.mtry=c(2,3,6:10,12:21)))
#print(m_rf)
plot(m_rf_loo,main="Modèle RandomForest")
```

Optimiser la méthode de forêt aléatoire avec la validation croisée "Leave One Out" n'est pas évidente. En effet, l'évaluation via un seul individu ne permet pas d'obtenir de résultat robuste dans ce cas là car le résultat dépend trop des variables choisies.

## Optimisation via Bootstrap

```{r}
train_control <- trainControl(method = "boot", number=100)
```

### Regression logistique

Pas sûr de la méthode sans avoir un tet après.

```{r,echo=FALSE}
m_glm<-train(progress~.,data = merge_data, method="glmStepAIC",trControl=train_control, trace=FALSE)
#print(m_glm)
print(m_glm)
```

### SVM

```{r}
m_svm_boot <- train(progress ~., data = merge_data, method="svmLinear",trControl=train_control,tuneGrid=data.frame(C=c(0.05,0.1,1:18)))
#print(m_svm)
plot(m_svm_boot,main="Modèle SVM")
```

On observe ici que l'optimisation du paramètre C avec le bootstrap renvoie le même résultat. On obtient des résultats équivalent. Le bootstrap n'apporte donc rien de plus que le leave one out.

### randomForest

```{r}
m_rf_boot<-train(progress ~., data = merge_data, method="rf",trControl=train_control,tuneGrid=expand.grid(.mtry=c(2,3,6:10,12:21)))
#print(m_rf)
plot(m_rf_boot,main="Modèle RandomForest")
```

Même si l'aspect aléatoire de cette méthode rend encore difficile l'évaluation, l'utilisation du bootstrap permet néanmoins d'observer pluqs facilement une tendance : la diminution de la précision à mesure que l'on rajoute des variables.